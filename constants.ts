import { WeekModule, ProjectTrack, RubricItem, DeploymentStep, LessonPlan, WorkshopGuide } from './types';

export const COURSE_TITLE = "AI Project 101";

export const WEEKLY_CONTENT: WeekModule[] = [
  {
    week: 1,
    title: "AI Kickoff: Lifecycle & Setup",
    description: "Understand the full AI lifecycle, setup your professional environment, and frame a solvable problem.",
    objectives: [
      "Differentiate AI/ML/DL & Understand Lifecycle",
      "Setup Professional Env (Repo, Venv, Colab)",
      "Create Project Charter with Success Metrics"
    ],
    concepts: ["AI Lifecycle", "Problem Framing", "Success Metrics", "PDPA/Privacy"],
    tools: ["Git/GitHub", "VS Code / Colab", "Python venv", "Jupyter"],
    workshop: "Repo Skeleton & Project Charter v0",
    deliverable: "Repo + Env Check Notebook + Project Charter",
    pitfalls: ["Skipping problem definition", "Using real PII data", "Not testing environment"]
  },
  {
    week: 2,
    title: "Baseline Model & Metrics",
    description: "Build your first reproducible baseline model, master Train/Test split, and understand key metrics (Accuracy vs F1).",
    objectives: [
      "Create a reproducible Baseline Model v1",
      "Master Train/Test Split (Stratify & Random State)",
      "Compare Metrics (Accuracy vs F1-macro) & Save Artifacts"
    ],
    concepts: ["Baseline Model", "Train/Test Split", "Data Leakage", "Accuracy vs F1", "Reproducibility"],
    tools: ["Scikit-learn", "Pandas", "Joblib", "JSON"],
    workshop: "Baseline v1 & Model Artifacts",
    deliverable: "Notebook (Baseline), Metrics JSON, Model Artifacts (joblib/meta), Updated README",
    pitfalls: ["Data Leakage", "Ignoring Class Imbalance", "Not setting random_state"]
  },
  {
    week: 3,
    title: "Data Pipeline & Feature Engineering",
    description: "Construct a reproducible data cleaning pipeline and engineer features to improve model performance.",
    objectives: [
      "Build a reproducible Data Pipeline (Cleaning + Scaling)",
      "Apply Feature Engineering (Scaling, Encoding)",
      "Train Model v2 with Pipeline"
    ],
    concepts: ["Data Pipeline", "Missing Values", "Outliers", "Scaling (StandardScaler)", "sklearn.pipeline"],
    tools: ["Scikit-learn Pipeline", "Pandas"],
    workshop: "Data Pipeline & Model v2",
    deliverable: "Processed Dataset, Notebook (Pipeline), Model v2 Artifacts, Comparison Report",
    pitfalls: ["Scaling before split (Leakage)", "Ignoring outliers"]
  },
  {
    week: 4,
    title: "Validation & Hyperparameter Tuning",
    description: "Master robust evaluation using Cross-Validation and optimize your model with GridSearchCV.",
    objectives: [
      "Implement Cross-Validation for robust evaluation",
      "Perform Hyperparameter Tuning (GridSearchCV)",
      "Select Model v3 based on CV Mean/Std"
    ],
    concepts: ["Cross-Validation", "Holdout Set", "Hyperparameter Tuning", "GridSearchCV", "Overfitting/Underfitting"],
    tools: ["Scikit-learn (GridSearchCV, cross_val_score)"],
    workshop: "Tuning & Model v3",
    deliverable: "Notebook (Tuning), CV Results CSV, Model v3 Artifacts, Comparison Report",
    pitfalls: ["Tuning on Test Set", "Ignoring CV Standard Deviation"]
  },
  {
    week: 5,
    title: "Error Analysis & Model Improvement",
    description: "Stop guessing. Analyze model errors systematically to drive data-centric improvements.",
    objectives: [
      "Perform systematic Error Analysis (Confusion Matrix, Error Table)",
      "Identify patterns in misclassifications",
      "Train Model v4 based on analysis insights"
    ],
    concepts: ["Error Analysis", "Confusion Matrix", "Precision/Recall Tradeoff", "Data-Centric AI", "Polynomial Features"],
    tools: ["Confusion Matrix Display", "Pandas (Filtering)"],
    workshop: "Error Analysis & Model v4",
    deliverable: "Error Analysis Report, Error Table CSV, Model v4 Artifacts, Comparison Report",
    pitfalls: ["Assuming accuracy is enough", "Not looking at actual error rows"]
  },
  {
    week: 6,
    title: "Production Readiness: Split & Threshold",
    description: "Prepare for the real world with proper Train/Val/Test splits, leakage checks, and threshold tuning.",
    objectives: [
      "Implement proper Train/Val/Test splits",
      "Select Decision Thresholds from Validation set",
      "Calibrate Probabilities (Basics)"
    ],
    concepts: ["Train/Val/Test", "Decision Threshold", "Calibration", "Data Leakage Checklist"],
    tools: ["Scikit-learn (CalibratedClassifierCV)", "Matplotlib"],
    workshop: "Split, Threshold & Model v5",
    deliverable: "Split Summary, Leakage Checklist, Threshold Policy, Model v5 Artifacts",
    pitfalls: ["Tuning threshold on Test set", "Leakage features"]
  },
  {
    week: 7,
    title: "API Deployment (FastAPI)",
    description: "Expose your model as a professional REST API with validation, logging, and testing.",
    objectives: [
      "Build a FastAPI service (/health, /predict)",
      "Implement Input Validation (Pydantic)",
      "Add Safe Logging & Error Handling"
    ],
    concepts: ["REST API", "Input Validation", "Serialization", "Logging vs Privacy"],
    tools: ["FastAPI", "Uvicorn", "Pydantic", "Pytest"],
    workshop: "FastAPI Implementation & Testing",
    deliverable: "API Code (main.py, schemas.py), Test Suite (test_api.py), API Documentation",
    pitfalls: ["Logging raw PII", "Missing input validation", "Hardcoding paths"]
  },
  {
    week: 8,
    title: "Web UI & Demo Day Prep",
    description: "Create an interactive web interface using Streamlit and prepare your final portfolio demo.",
    objectives: [
      "Build a Streamlit UI connecting to your API",
      "Handle UX States (Loading, Error, Success)",
      "Create a Demo Pack for Portfolio"
    ],
    concepts: ["Frontend-Backend Integration", "User Experience (UX)", "State Management"],
    tools: ["Streamlit", "Requests"],
    workshop: "Streamlit UI & Demo Pack",
    deliverable: "UI Code (app.py), Demo Checklist, Usage Guide, Updated README",
    pitfalls: ["Direct model loading in UI (Bypassing API)", "Poor error messaging"]
  },
  {
    week: 9,
    title: "Docker Containerization",
    description: "Package your API and UI into portable Docker containers and orchestrate them with Docker Compose.",
    objectives: [
      "Create Dockerfiles for FastAPI and Streamlit",
      "Orchestrate multi-container apps with Docker Compose",
      "Implement Healthchecks and Runbooks"
    ],
    concepts: ["Containerization", "Docker Compose", "Healthchecks", "Environment Variables"],
    tools: ["Docker", "Docker Desktop"],
    workshop: "Containerize API & UI",
    deliverable: "Dockerfile.api, Dockerfile.ui, docker-compose.yml, Runbook",
    pitfalls: ["Port conflicts", "Incorrect API URL in UI", "Large image sizes", "Docker daemon not running"]
  },
  {
    week: 10,
    title: "Cloud Deployment & CI/CD",
    description: "Deploy your app to the cloud securely and automate your testing workflow.",
    objectives: [
      "Deploy to Streamlit Cloud (Public/Private)",
      "Manage Secrets/API Keys securely",
      "Set up Basic CI/CD (GitHub Actions)"
    ],
    concepts: ["Cloud PaaS", "Secrets Management", "CI/CD", "Continuous Integration"],
    tools: ["Streamlit Cloud", "GitHub Actions", "YAML"],
    workshop: "Cloud Deploy & CI Setup",
    deliverable: "Live App URL, Secrets Config, .github/workflows/main.yml",
    pitfalls: ["Committing .env/secrets to GitHub", "Ignoring build failures", "Hardcoding production URLs"]
  },
  {
    week: 11,
    title: "Monitoring & Basic MLOps",
    description: "Implement real-world monitoring, structured logging, and incident response procedures.",
    objectives: [
      "Design privacy-safe structured logging (JSONL)",
      "Calculate key metrics (Error Rate, Latency)",
      "Create a monitoring dashboard and incident runbook"
    ],
    concepts: ["Structured Logging", "Golden Metrics", "Model Versioning", "Drift Signals"],
    tools: ["Python Logging", "JSONL", "Pandas", "Streamlit"],
    workshop: "Logs, Metrics & Dashboard",
    deliverable: "api/logger.py, src/metrics.py, monitor/app.py, Runbook, Privacy Policy",
    pitfalls: ["Logging PII/Raw features", "Unstructured logs", "No timezone handling", "Alert fatigue"]
  },
  {
    week: 12,
    title: "Capstone Wrap-up (Enterprise)",
    description: "Finalize your project with enterprise-grade documentation, portfolio assets, and a v1.0.0 release.",
    objectives: [
      "Create a professional README and portfolio assets (Demo URL/Video)",
      "Complete enterprise docs: Charter, Datasheet, Model Card, Test Plan, Runbook",
      "Perform Final QA (Security/PDPA) and create a Release Tag (v1.0.0)"
    ],
    concepts: ["Portfolio Storytelling", "Model Governance", "Release Management", "Security/PDPA Checklist"],
    tools: ["Git Tags", "Markdown", "Video Recording", "Presentation"],
    workshop: "Finalize Docs & Release",
    deliverable: "README, Enterprise Docs, v1.0.0 Tag, Demo Assets",
    pitfalls: ["Vague README", "Broken demo links", "Docs mismatch code", "Logging PII"]
  }
];

export const PROJECT_TRACKS: ProjectTrack[] = [
  {
    id: "track-1",
    title: "Chatbot / NLP Assistant",
    icon: "üí¨",
    description: "Build intelligent assistants: Legal QA, News Summarizers, or Shopping Guides.",
    difficulty: "Intermediate",
    techStack: ["Python", "Hugging Face", "OpenAI/Gemini API", "Streamlit", "LangChain"],
    useCase: "Customer Support, Personal Assistant"
  },
  {
    id: "track-2",
    title: "Image Recognition / CV",
    icon: "üëÅÔ∏è",
    description: "Detect objects and patterns: Quality Control, Face Mask Detection, Plant Disease.",
    difficulty: "Intermediate",
    techStack: ["Python", "TensorFlow/Keras", "OpenCV", "Roboflow", "Streamlit"],
    useCase: "Manufacturing, Security, AgTech"
  },
  {
    id: "track-3",
    title: "Predictive Analytics",
    icon: "üìä",
    description: "Turn data into foresight: Sales Forecasting, Churn Prediction, Stock Prices.",
    difficulty: "Beginner",
    techStack: ["Python", "Pandas", "Scikit-learn", "XGBoost", "Streamlit"],
    useCase: "Business Intelligence, Finance"
  },
  {
    id: "track-4",
    title: "IoT & Edge AI",
    icon: "ü§ñ",
    description: "AI on devices: People Counting, Voice Control (Simulated or Real).",
    difficulty: "Advanced",
    techStack: ["Python", "TensorFlow Lite", "Raspberry Pi", "MQTT", "Flask"],
    useCase: "Smart Home, Smart City, IoT"
  }
];

export const ASSESSMENT_RUBRICS: RubricItem[] = [
  {
    category: "Weekly Assignments (40%)",
    weight: "40%",
    criteria: [
      "On-time submission (Week 1-7)",
      "Completeness of tasks",
      "Code runs without errors"
    ]
  },
  {
    category: "Final Project: Technical (30%)",
    weight: "30%",
    criteria: [
      "Model complexity and correctness",
      "Code quality (Clean Code)",
      "Data handling and preprocessing"
    ]
  },
  {
    category: "Final Project: Usability (20%)",
    weight: "20%",
    criteria: [
      "User Interface (UI) usability",
      "No critical bugs during usage",
      "Problem-solving impact"
    ]
  },
  {
    category: "Presentation & Portfolio (10%)",
    weight: "10%",
    criteria: [
      "Professional README",
      "Engaging presentation",
      "Clear Demo Video"
    ]
  }
];

export const DEPLOYMENT_GUIDE: DeploymentStep[] = [
  {
    title: "Step 1: Code Preparation",
    description: "Ensure `app.py` and `requirements.txt` are ready.",
    codeSnippet: "# requirements.txt\nstreamlit\npandas\nscikit-learn\ntensorflow-cpu"
  },
  {
    title: "Step 2: Push to GitHub",
    description: "Create a repository and push your code. Don't forget `.gitignore`.",
    codeSnippet: "git init\ngit add .\ngit commit -m 'Initial commit'\ngit push origin main"
  },
  {
    title: "Step 3: Connect to Streamlit Cloud",
    description: "Log in to share.streamlit.io, select your repo, and deploy.",
    codeSnippet: ""
  },
  {
    title: "Step 4: Monitoring",
    description: "Check logs in the Streamlit dashboard. Fix errors and push to redeploy automatically."
  }
];

export const PRICING_PLANS = [
  {
    name: "Standard",
    priceTH: "‡∏ø3,900",
    priceEN: "$119",
    descriptionTH: "‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏ô‡πÄ‡∏≠‡∏á",
    descriptionEN: "For self-paced learners.",
    featuresTH: ["‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î‡∏ä‡∏µ‡∏û", "‡∏ó‡∏≥ Workshop ‡∏Ñ‡∏£‡∏ö 12 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå", "‡πÅ‡∏ö‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö & ‡πÄ‡∏â‡∏•‡∏¢", "‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á (Certificate)"],
    featuresEN: ["Lifetime Access", "All 12 Workshops", "Quizzes & Solutions", "Completion Certificate"],
    ctaTH: "‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô",
    ctaEN: "Enroll Standard",
    highlight: false
  },
  {
    name: "Pro Mentorship",
    priceTH: "‡∏ø8,900",
    priceEN: "$249",
    descriptionTH: "‡πÄ‡∏ô‡πâ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏û‡∏µ‡πà‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß",
    descriptionEN: "Accelerate with expert guidance.",
    featuresTH: ["‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô Standard", "‡∏ï‡∏£‡∏ß‡∏à‡πÇ‡∏Ñ‡πâ‡∏î‡∏£‡∏≤‡∏¢‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå", "Live Q&A ‡∏ó‡∏∏‡∏Å 2 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå", "‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤ Capstone ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß 1-on-1"],
    featuresEN: ["Everything in Standard", "Weekly Code Review", "Bi-weekly Live Q&A", "1-on-1 Capstone Consult"],
    ctaTH: "‡∏™‡∏°‡∏±‡∏Ñ‡∏£ Pro",
    ctaEN: "Enroll Pro",
    highlight: true
  }
];

export const WEEK_1_LESSON_PLAN: LessonPlan = {
  week: 1,
  topic: "Kickoff + Setup + Problem Framing",
  timeline: [
    { time: "0:00 - 0:10", activity: "Course Kickoff", detail: "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 12 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå: ‡∏™‡∏£‡πâ‡∏≤‡∏á Portfolio ‡∏à‡∏£‡∏¥‡∏á (Repo + Demo + Docs)" },
    { time: "0:10 - 0:35", activity: "Theory: AI/ML/DL", detail: "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á AI, ML, DL ‡πÅ‡∏•‡∏∞ Use Case ‡∏à‡∏£‡∏¥‡∏á (Chatbot, Vision, IoT)" },
    { time: "0:35 - 0:55", activity: "AI Project Lifecycle", detail: "Problem -> Data -> Model -> Eval -> Deploy -> Monitor -> Iterate" },
    { time: "1:05 - 1:35", activity: "Problem Framing", detail: "‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (Problem), ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (User), ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (Value)" },
    { time: "1:35 - 2:05", activity: "Metrics & Success", detail: "‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î (F1, Accuracy, Latency) ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ" },
    { time: "2:05 - 2:20", activity: "Ethics & PDPA", detail: "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡πá‡∏ö (PII), ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Open Dataset, ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£ Log ‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢" },
    { time: "2:30 - 3:20", activity: "Live Demo", detail: "‡∏™‡∏£‡πâ‡∏≤‡∏á Repo Skeleton, Setup Venv, ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô Baseline EDA ‡πÅ‡∏£‡∏Å" },
    { time: "3:20 - 4:50", activity: "Workshop: Hands-on", detail: "‡∏™‡∏£‡πâ‡∏≤‡∏á Env Check Notebook, EDA Mini-report, ‡πÅ‡∏•‡∏∞ Project Charter v0" },
    { time: "5:00 - 5:30", activity: "Peer Review", detail: "‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏ï‡∏£‡∏ß‡∏à Project Charter: Metric ‡∏ß‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°? Scope ‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏õ‡πÑ‡∏´‡∏°?" },
    { time: "5:50 - 6:00", activity: "Wrap-up & Quiz", detail: "‡∏™‡∏£‡∏∏‡∏õ Deliverables ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ Quiz ‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏ó" }
  ],
  contentSummary: [
    {
      title: "AI vs ML vs DL",
      points: [
        "AI: ‡∏Ñ‡∏≥‡∏Å‡∏ß‡πâ‡∏≤‡∏á = ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á '‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏â‡∏•‡∏≤‡∏î'",
        "ML: ‡πÉ‡∏´‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•' (‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢/‡∏à‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó)",
        "DL: ML ‡∏™‡∏≤‡∏¢ '‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏•‡∏∂‡∏Å' ‡πÄ‡∏Å‡πà‡∏á‡∏†‡∏≤‡∏û/‡πÄ‡∏™‡∏µ‡∏¢‡∏á/‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"
      ]
    },
    {
      title: "Project Lifecycle (‡∏ß‡∏á‡∏à‡∏£‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)",
      points: [
        "1. Problem Framing: ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏≠‡∏∞‡πÑ‡∏£ ‡πÉ‡∏´‡πâ‡πÉ‡∏Ñ‡∏£ ‡∏ß‡∏±‡∏î‡∏ú‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏á",
        "2. Data: ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PII ‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå",
        "3. Model: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å Baseline ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏Å‡πà‡∏≠‡∏ô",
        "4. Evaluate: ‡πÅ‡∏¢‡∏Å Train/Test ‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏à‡∏∏‡∏î",
        "5. Deploy & Monitor: ‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•"
      ]
    }
  ],
  demoScript: [
    {
      step: "1. Repo Setup (Local)",
      description: "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô",
      code: "mkdir ai-project-101\ncd ai-project-101\nmkdir data notebooks src docs reports\nni README.md\nni requirements.txt"
    },
    {
      step: "2. Env Setup",
      description: "‡∏™‡∏£‡πâ‡∏≤‡∏á Venv ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Libraries",
      code: "python -m venv .venv\n.\\.venv\\Scripts\\Activate.ps1\npip install numpy pandas matplotlib scikit-learn jupyter"
    },
    {
      step: "3. First EDA",
      description: "‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wine ‡πÅ‡∏•‡∏∞‡∏û‡∏•‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô",
      code: "from sklearn.datasets import load_wine\nimport matplotlib.pyplot as plt\ndf = load_wine(as_frame=True).frame\nprint(df.head())\ndf['target'].value_counts().plot(kind='bar')\nplt.show()"
    }
  ],
  workshopSteps: [
    { 
        title: "Workshop A: Env Check", 
        steps: [
            "‡∏™‡∏£‡πâ‡∏≤‡∏á 'notebooks/01_env_check.ipynb'", 
            "Import sys, numpy, pandas, sklearn ‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô", 
            "‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Error ‡∏à‡∏∂‡∏á‡∏à‡∏∞‡∏ú‡πà‡∏≤‡∏ô"
        ] 
    },
    { 
        title: "Workshop B: Mini EDA", 
        steps: [
            "‡πÇ‡∏´‡∏•‡∏î Dataset ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (Wine ‡∏´‡∏£‡∏∑‡∏≠ Iris)", 
            "‡πÉ‡∏ä‡πâ .describe(), .shape, .value_counts()", 
            "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏£‡∏∏‡∏õ 5 ‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏•‡∏á‡πÉ‡∏ô 'reports/week1_eda_notes.md'"
        ] 
    },
    { 
        title: "Workshop C: Project Charter v0", 
        steps: [
            "‡∏™‡∏£‡πâ‡∏≤‡∏á 'docs/project_charter_v0.md'", 
            "‡∏£‡∏∞‡∏ö‡∏∏ Problem, Target Users, Success Metrics (‡πÄ‡∏ä‡πà‡∏ô F1 > 0.8)", 
            "‡∏£‡∏∞‡∏ö‡∏∏ Scope (In/Out) ‡πÅ‡∏•‡∏∞ Data Plan (‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, PII)"
        ] 
    }
  ],
  exercises: [
    { level: "Easy", title: "One-sentence Value", description: "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô 'One-sentence value' ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÉ‡∏´‡πâ‡∏Ñ‡∏° 3 ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô" },
    { level: "Medium", title: "Define Metrics", description: "‡∏Å‡∏≥‡∏´‡∏ô‡∏î Metric ‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏ä‡πà‡∏ô Accuracy) ‡πÅ‡∏•‡∏∞ Metric ‡∏£‡∏≠‡∏á (‡πÄ‡∏ä‡πà‡∏ô Latency) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢" },
    { level: "Challenge", title: "Scope Cut Plan", description: "‡∏£‡∏∞‡∏ö‡∏∏‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞ '‡πÑ‡∏°‡πà‡∏ó‡∏≥' (Out-of-scope) ‡∏°‡∏≤ 5 ‡∏Ç‡πâ‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏ó‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤" }
  ],
  debugCorner: [
    { problem: "Activate.ps1 cannot be loaded", solution: "‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: Set-ExecutionPolicy -Scope CurrentUser RemoteSigned" },
    { problem: "ModuleNotFoundError", solution: "‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏° Activate venv ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô Jupyter ‡∏´‡∏£‡∏∑‡∏≠ pip install" },
    { problem: "Plot ‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô Notebook", solution: "‡πÉ‡∏™‡πà plt.show() ‡∏ó‡∏µ‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Cell ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ %matplotlib inline" }
  ],
  quiz: [
    { id: 1, question: "AI Project Lifecycle ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡πÉ‡∏î?", options: ["Model->Data->Problem", "Problem->Data->Model->Eval->Deploy", "Data->Deploy->Model", "Eval->Problem->Data"], correctAnswer: 1, explanation: "Lifecycle ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å Problem ‡πÄ‡∏™‡∏°‡∏≠ ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ Data -> Model -> Eval -> Deploy" },
    { id: 2, question: "‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Success Metrics?", options: ["‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏¢‡∏≤‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô", "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡∏∞‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏á‡∏ó‡∏≤‡∏á", "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏ß‡∏¢", "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ install ‡πÑ‡∏î‡πâ"], correctAnswer: 1, explanation: "‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏ß‡∏±‡∏î ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡∏µ‡∏û‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á" },
    { id: 3, question: "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠ PII ‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ?", options: ["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™", "‡∏Ñ‡πà‡∏≤ F1", "‡πÄ‡∏•‡∏Ç‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß"], correctAnswer: 2, explanation: "PII (Personally Identifiable Information) ‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡πÑ‡∏î‡πâ ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á PDPA" },
    { id: 4, question: "Deliverable ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á Week 1 ‡∏Ñ‡∏∑‡∏≠?", options: ["Model 99% Acc", "Repo ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ + Charter ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô", "UI ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°", "Docker Image"], correctAnswer: 1, explanation: "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô (Framing) ‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏î‡∏¥‡∏ô‡∏ï‡πà‡∏≠" },
    { id: 5, question: "‡∏ñ‡πâ‡∏≤ import library ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏°‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å?", options: ["Dataset ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô", "‡πÉ‡∏ä‡πâ Python ‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà install", "Metrics ‡∏ú‡∏¥‡∏î", "Scope ‡∏Å‡∏ß‡πâ‡∏≤‡∏á"], correctAnswer: 1, explanation: "‡∏°‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ activate virtual environment (venv)" }
  ]
};

export const WEEK_2_LESSON_PLAN: LessonPlan = {
  week: 2,
  topic: "Baseline Model & Metrics",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap & Goals", detail: "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô Week 1 (Repo, Charter) ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ: Model v1 ‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á" },
    { time: "0:10 - 0:25", activity: "Theory: Baseline", detail: "Baseline ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏Å‡πà‡∏≠‡∏ô? (Logistic Regression/RandomForest)" },
    { time: "0:25 - 0:45", activity: "Split Strategy", detail: "Train/Test Split, Data Leakage, Random State ‡πÅ‡∏•‡∏∞ Stratify" },
    { time: "0:45 - 1:00", activity: "Metrics", detail: "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Metric ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å: Accuracy vs F1-macro (Class Imbalance)" },
    { time: "1:00 - 1:25", activity: "Live Demo 1", detail: "‡∏™‡∏£‡πâ‡∏≤‡∏á Baseline ‡πÉ‡∏ô Notebook: Load -> Split -> Train -> Evaluate" },
    { time: "1:25 - 2:00", activity: "Workshop A", detail: "Hands-on: ‡∏™‡∏£‡πâ‡∏≤‡∏á Notebook 02_baseline_v1 ‡πÅ‡∏•‡∏∞‡πÄ‡∏ã‡∏ü reports/metrics_v1.json" },
    { time: "2:00 - 2:25", activity: "Live Demo 2", detail: "‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Model Artifacts (joblib, features.json, meta.json) ‡πÅ‡∏ö‡∏ö‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û" },
    { time: "2:25 - 2:45", activity: "Workshop B", detail: "Reproducibility Check: ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏≤‡πÄ‡∏ó‡∏™ & ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï README" },
    { time: "2:50 - 3:00", activity: "Wrap-up & Quiz", detail: "‡∏™‡∏£‡∏∏‡∏õ Deliverables ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ Quiz ‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏ó" }
  ],
  contentSummary: [
    {
      title: "Baseline Model",
      points: [
        "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà '‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô",
        "‡∏ñ‡πâ‡∏≤‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ baseline = ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏à‡∏£‡∏¥‡∏á",
        "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: Logistic Regression (‡πÄ‡∏£‡πá‡∏ß, ‡∏á‡πà‡∏≤‡∏¢), RandomForest (‡πÅ‡∏£‡∏á, ‡πÉ‡∏ä‡πâ‡∏™‡∏∞‡∏î‡∏ß‡∏Å)"
      ]
    },
    {
      title: "Train/Test Split",
      points: [
        "Train: ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ",
        "Test: ‡∏ß‡∏±‡∏î‡∏Å‡∏≤‡∏£ Generalize (‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î)",
        "random_state: ‡∏•‡πá‡∏≠‡∏Å‡∏ú‡∏•‡∏™‡∏∏‡πà‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°",
        "stratify: ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°"
      ]
    },
    {
      title: "Metrics",
      points: [
        "Accuracy: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏ß‡∏° (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏°‡∏î‡∏∏‡∏•)",
        "F1-macro: ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ F1 ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™ (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•)"
      ]
    }
  ],
  demoScript: [
    {
      step: "1. Load & Split",
      description: "‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á Train/Test ‡πÅ‡∏ö‡∏ö Stratified",
      code: "X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)"
    },
    {
      step: "2. Train & Eval",
      description: "‡πÄ‡∏ó‡∏£‡∏ô Logistic Regression ‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏î‡∏ú‡∏•",
      code: "model = LogisticRegression(max_iter=800)\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\nprint(classification_report(y_test, pred))"
    },
    {
      step: "3. Save Artifacts",
      description: "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Metadata",
      code: "joblib.dump(model, 'models/v1/model.joblib')\njson.dump(features, open('models/v1/features.json', 'w'))"
    }
  ],
  workshopSteps: [
    {
      title: "Workshop A: Baseline v1",
      steps: [
        "‡∏™‡∏£‡πâ‡∏≤‡∏á 'notebooks/02_baseline_v1.ipynb'",
        "‡∏ó‡∏≥ Load -> Split -> Train -> Evaluate",
        "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏• 'reports/metrics_v1.json'"
      ]
    },
    {
      title: "Workshop B: Artifacts & Docs",
      steps: [
        "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå 'models/v1/'",
        "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å model.joblib, features.json, meta.json",
        "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï README.md ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô 'How to Run Baseline'"
      ]
    }
  ],
  exercises: [
    { level: "Easy", title: "Change Split", description: "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô test_size ‡πÄ‡∏õ‡πá‡∏ô 0.3 ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡∏≠‡∏á Metric" },
    { level: "Medium", title: "Compare Models", description: "‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ RandomForestClassifier ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö F1-macro ‡∏Å‡∏±‡∏ö LogisticRegression" },
    { level: "Challenge", title: "Pipeline", description: "‡∏ó‡∏≥ Pipeline ‡πÉ‡∏™‡πà StandardScaler ‡∏Å‡πà‡∏≠‡∏ô LogisticRegression ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå" }
  ],
  debugCorner: [
    { problem: "ConvergenceWarning", solution: "‡πÄ‡∏û‡∏¥‡πà‡∏° max_iter=800 ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ StandardScaler" },
    { problem: "ValueError: The least populated class...", solution: "‡∏•‡∏î test_size ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà" },
    { problem: "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (0.99+)", solution: "‡πÄ‡∏ä‡πá‡∏Ñ Data Leakage ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ú‡∏•‡∏≠‡πÄ‡∏≠‡∏≤ Target ‡πÄ‡∏Ç‡πâ‡∏≤ Feature" }
  ],
  quiz: [
    { id: 1, question: "Baseline model ‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡πÑ‡∏î‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ", "‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏∏‡πà‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ", "‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô test set", "‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ data"], correctAnswer: 1, explanation: "Baseline ‡∏Ñ‡∏∑‡∏≠‡∏à‡∏∏‡∏î‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°" },
    { id: 2, question: "random_state ‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô", "‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á", "‡πÄ‡∏û‡∏¥‡πà‡∏° F1 ‡πÄ‡∏™‡∏°‡∏≠", "‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå Reproducible (‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ)" },
    { id: 3, question: "stratify=y ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£?", options: ["‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà", "‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡πÉ‡∏ô Train/Test", "‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô DL", "‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"], correctAnswer: 1, explanation: "‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Imbalanced Data ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Train/Test ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô" },
    { id: 4, question: "F1-macro ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠?", options: ["‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏°‡∏î‡∏∏‡∏•", "‡∏Ñ‡∏•‡∏≤‡∏™‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•", "‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏ß‡∏¢", "Regression ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"], correctAnswer: 1, explanation: "Macro average ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô ‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•" },
    { id: 5, question: "‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á Save Model?", options: ["‡πÉ‡∏´‡πâ Notebook ‡∏™‡∏±‡πâ‡∏ô", "‡πÄ‡∏û‡∏∑‡πà‡∏≠ Deploy/Inference ‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á", "‡πÄ‡∏û‡∏¥‡πà‡∏° Accuracy", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Metrics"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡∏°‡πà" },
    { id: 6, question: "‡πÑ‡∏ü‡∏•‡πå features.json ‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û", "‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ç‡∏ç‡∏≤ (Contract) ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå", "‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", "‡πÄ‡∏Å‡πá‡∏ö Secret"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ô Predict ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á Feature ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£" },
    { id: 7, question: "joblib.dump ‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£?", options: ["‡πÇ‡∏´‡∏•‡∏î Dataset", "‡πÄ‡∏ã‡∏ü‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå", "Plot Graph", "‡∏ó‡∏≥ API"], correctAnswer: 1, explanation: "Standard library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö serialize Python objects (Models)" },
    { id: 8, question: "‡∏Ç‡πâ‡∏≠‡πÉ‡∏î‡∏Ñ‡∏∑‡∏≠ Train/Test Split ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å?", options: ["‡πÉ‡∏ä‡πâ Test ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•", "‡πÉ‡∏ä‡πâ Train ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô, Test ‡∏ß‡∏±‡∏î‡∏ú‡∏•", "‡πÉ‡∏ä‡πâ Test ‡πÄ‡∏ó‡∏£‡∏ô", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Split"], correctAnswer: 1, explanation: "‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ Test Set ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î (Data Leakage)" },
    { id: 9, question: "‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏£‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏≠‡∏∞‡πÑ‡∏£?", options: ["GPU ‡πÅ‡∏£‡∏á", "Data Leakage", "Jupyter ‡∏ä‡πâ‡∏≤", "Python ‡πÉ‡∏´‡∏°‡πà"], correctAnswer: 1, explanation: "‡∏°‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å Leakage ‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏™‡πà‡πÉ‡∏ô‡πÇ‡∏à‡∏ó‡∏¢‡πå" },
    { id: 10, question: "Week 2 Deliverable ‡∏Ñ‡∏∑‡∏≠?", options: ["Notebook ‡πÄ‡∏õ‡∏•‡πà‡∏≤", "Baseline Metrics + Artifacts + README", "UI ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°", "Docker"], correctAnswer: 1, explanation: "‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÑ‡∏î‡πâ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ" }
  ]
};

export const WEEK_3_LESSON_PLAN: LessonPlan = {
  week: 3,
  topic: "Data Pipeline + Model v2",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 2", detail: "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô v1: Split -> Train -> Metrics -> Save" },
    { time: "0:10 - 0:25", activity: "Theory: Data Pipeline", detail: "‡∏ó‡∏≥‡πÑ‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏∞‡∏≠‡∏≤‡∏î? Pipeline ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Data Contract?" },
    { time: "0:25 - 0:45", activity: "Cleaning & Validation", detail: "Missing, Outlier, Duplicate, Type checking (Data Contract)" },
    { time: "0:45 - 1:00", activity: "Feature Engineering", detail: "Scaling (StandardScaler) ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Feature ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô" },
    { time: "1:00 - 1:25", activity: "Live Demo 1", detail: "‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline (Scaler -> LogReg) ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö v1 vs v2" },
    { time: "1:25 - 2:00", activity: "Workshop A", detail: "‡∏™‡∏£‡πâ‡∏≤‡∏á Processed Dataset (data/processed/wine_v1.csv) ‡πÅ‡∏•‡∏∞ Notebook Pipeline" },
    { time: "2:00 - 2:25", activity: "Live Demo 2", detail: "Save Artifacts v2 (Model + Features + Meta + Config)" },
    { time: "2:25 - 2:45", activity: "Workshop B", detail: "Compare Report v1 vs v2 ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï README" },
    { time: "2:50 - 3:00", activity: "Wrap-up & Quiz", detail: "‡∏ï‡∏£‡∏ß‡∏à DoD ‡πÅ‡∏•‡∏∞ Quiz" }
  ],
  contentSummary: [
    { title: "Data Pipeline", points: ["‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏° train ‡πÅ‡∏ö‡∏ö '‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ'", "‡∏•‡∏î‡∏á‡∏≤‡∏ô‡∏°‡∏∑‡∏≠ (Manual work) ‡πÅ‡∏•‡∏∞ Human Error"] },
    { title: "Cleaning Checklist", points: ["Missing values, Duplicates, Outliers, Column types"] },
    { title: "Feature Engineering (Basic)", points: ["StandardScaler: ‡∏õ‡∏£‡∏±‡∏ö Mean=0, Std=1 ‡∏ä‡πà‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• Linear", "Pipeline: ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Data Leakage (Fit train, Transform test)"] }
  ],
  demoScript: [
    { step: "1. Pipeline v2", description: "‡πÉ‡∏ä‡πâ sklearn.pipeline ‡∏£‡∏ß‡∏° Scaler ‡πÅ‡∏•‡∏∞ Model", code: "pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression())])\npipe.fit(X_train, y_train)" },
    { step: "2. Save Processed Data", description: "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏µ‡∏ô‡πÅ‡∏•‡πâ‡∏ß", code: "df.to_csv('data/processed/wine_v1.csv', index=False)" },
    { step: "3. Save Artifacts v2", description: "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Metadata v2", code: "joblib.dump(pipe, 'models/v2/model.joblib')\njson.dump(meta, open('models/v2/meta.json', 'w'))" }
  ],
  workshopSteps: [
    { title: "Workshop A: Pipeline & Data", steps: ["‡∏™‡∏£‡πâ‡∏≤‡∏á notebooks/03_data_pipeline_v2.ipynb", "Check missing/duplicates", "Save data/processed/wine_v1.csv"] },
    { title: "Workshop B: Artifacts v2", steps: ["Train Pipeline(Scaler->Model)", "Save models/v2/ artifacts", "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô reports/compare_v1_v2.md"] }
  ],
  exercises: [
    { level: "Easy", title: "MinMaxScaler", description: "‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô StandardScaler ‡πÄ‡∏õ‡πá‡∏ô MinMaxScaler ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå" },
    { level: "Medium", title: "SelectKBest", description: "‡πÄ‡∏û‡∏¥‡πà‡∏° Feature Selection (SelectKBest) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Pipeline" },
    { level: "Challenge", title: "ColumnTransformer", description: "‡∏ó‡∏≥ Pipeline ‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Numerical ‡πÅ‡∏•‡∏∞ Categorical Columns" }
  ],
  debugCorner: [
    { problem: "ConvergenceWarning", solution: "‡πÄ‡∏û‡∏¥‡πà‡∏° max_iter ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Scaler ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á" },
    { problem: "Score ‡∏•‡∏î‡∏•‡∏á", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Data Leakage ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Pipeline" },
    { problem: "Save path error", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå models/v2 ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß (mkdir)" }
  ],
  quiz: [
    { id: 1, question: "Data pipeline ‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡∏ó‡∏≥‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏ß‡∏¢", "‡∏ó‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ metrics"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ" },
    { id: 2, question: "‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á save data/processed?", options: ["‡πÉ‡∏´‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô", "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏£‡∏±‡∏ô‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡∏°‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô", "‡πÄ‡∏û‡∏¥‡πà‡∏° accuracy", "‡πÉ‡∏´‡πâ docker ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"], correctAnswer: 1, explanation: "‡πÄ‡∏õ‡πá‡∏ô Single Source of Truth ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô" },
    { id: 3, question: "Pipeline ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏∏‡∏î?", options: ["‡∏ó‡∏≥ DL", "‡∏Å‡∏±‡∏ô Data Leakage", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Split", "‡πÉ‡∏ä‡πâ GPU"], correctAnswer: 1, explanation: "Pipeline ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ Preprocessing (‡πÄ‡∏ä‡πà‡∏ô Scaling) ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Split ‡πÄ‡∏™‡∏°‡∏≠" },
    { id: 4, question: "StandardScaler ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£?", options: ["Mean=0, Std=1", "0-1", "Text to Int", "Delete Data"], correctAnswer: 0, explanation: "‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡πÄ‡∏Å‡∏•‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (Z-score normalization)" },
    { id: 5, question: "‡πÑ‡∏ü‡∏•‡πå meta.json ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏≠‡∏∞‡πÑ‡∏£?", options: ["Password", "Config/Metrics/Version", "Images", "Ads"], correctAnswer: 1, explanation: "Metadata ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£" },
    { id: 6, question: "‡∏Ç‡πâ‡∏≠‡πÉ‡∏î‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ Data ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥?", options: ["‡∏î‡∏π‡∏™‡∏µ", "Missing/Duplicate/Outlier", "Train ‡πÄ‡∏•‡∏¢", "Deploy ‡πÄ‡∏•‡∏¢"], correctAnswer: 1, explanation: "‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏™‡∏°‡∏≠" },
    { id: 7, question: "Feature Engineering ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡πâ‡∏°‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LogReg?", options: ["GPU", "Scaling", "Images", "Audio"], correctAnswer: 1, explanation: "Linear Model ‡∏≠‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏ï‡πà‡∏≠‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å" },
    { id: 8, question: "Scaling ‡∏Å‡πà‡∏≠‡∏ô Split ‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏≠‡∏∞‡πÑ‡∏£?", options: ["Data Leakage", "RAM ‡πÄ‡∏ï‡πá‡∏°", "Net ‡∏ä‡πâ‡∏≤", "PII"], correctAnswer: 0, explanation: "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Test set ‡∏à‡∏∞‡∏£‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏´‡∏≤ Train set ‡∏ú‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤ Mean/Std ‡∏£‡∏ß‡∏°" },
    { id: 9, question: "Compare Report ‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡∏£‡∏Å Repo", "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ", "‡πÅ‡∏ó‡∏ô Metrics", "‡πÅ‡∏ó‡∏ô Readme"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏° v2 ‡∏ñ‡∏∂‡∏á‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ v1" },
    { id: 10, question: "Week 3 DoD ‡∏Ñ‡∏∑‡∏≠?", options: ["Notebook ‡πÄ‡∏õ‡∏•‡πà‡∏≤", "Processed Data + Pipeline v2 + Artifacts", "UI", "Docker"], correctAnswer: 1, explanation: "‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á Data, Model, ‡πÅ‡∏•‡∏∞ Report" }
  ]
};

export const WEEK_4_LESSON_PLAN: LessonPlan = {
  week: 4,
  topic: "Validation + Tuning + Model v3",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 3", detail: "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô v2: Pipeline, Processed Data" },
    { time: "0:10 - 0:30", activity: "Theory: Validation", detail: "Holdout Test (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡∏∞) vs Cross-Validation" },
    { time: "0:30 - 0:45", activity: "Metrics & Selection", detail: "F1-macro, Mean/Std ‡∏à‡∏≤‡∏Å CV (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)" },
    { time: "0:45 - 1:10", activity: "Live Demo 1", detail: "Cross-Validation ‡∏Å‡∏±‡∏ö Pipeline (cross_val_score)" },
    { time: "1:10 - 1:35", activity: "Live Demo 2", detail: "GridSearchCV: Tuning Hyperparameters" },
    { time: "1:35 - 2:10", activity: "Workshop A", detail: "‡∏ó‡∏≥ GridSearchCV ‡∏´‡∏≤ Best Params ‡πÅ‡∏•‡∏∞‡πÄ‡∏ã‡∏ü CV Results" },
    { time: "2:10 - 2:35", activity: "Live Demo 3", detail: "Train Final v3 (Best Est) + Test Eval (Once) + Save Artifacts" },
    { time: "2:35 - 2:55", activity: "Workshop B", detail: "Compare v2 vs v3 Report ‡πÅ‡∏•‡∏∞ Update README" },
    { time: "2:55 - 3:00", activity: "Wrap-up & Quiz", detail: "‡∏™‡∏£‡∏∏‡∏õ DoD ‡πÅ‡∏•‡∏∞ Quiz" }
  ],
  contentSummary: [
    { title: "Cross-Validation", points: ["‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≠‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", "‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ü‡∏•‡∏∏‡πä‡∏Ñ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Split"] },
    { title: "GridSearchCV", points: ["‡∏•‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏∏‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö", "‡πÉ‡∏ä‡πâ CV ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"] },
    { title: "Holdout Test Set", points: ["‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏à‡∏π‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î (‡∏Å‡∏±‡∏ô Overfitting/Leakage)"] }
  ],
  demoScript: [
    { step: "1. Cross-Validation", description: "‡πÉ‡∏ä‡πâ cross_val_score ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£", code: "scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='f1_macro')" },
    { step: "2. GridSearchCV", description: "‡∏à‡∏π‡∏ô C ‡∏Ç‡∏≠‡∏á LogisticRegression", code: "search = GridSearchCV(pipe, param_grid={'clf__C': [0.1, 1, 10]}, cv=5)\nsearch.fit(X_train, y_train)" },
    { step: "3. Final Evaluation", description: "‡∏ß‡∏±‡∏î‡∏ú‡∏• Test Set ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß", code: "best_model = search.best_estimator_\nacc = accuracy_score(y_test, best_model.predict(X_test))" }
  ],
  workshopSteps: [
    { title: "Workshop A: Tuning", steps: ["‡∏™‡∏£‡πâ‡∏≤‡∏á notebooks/04_cv_tuning_v3.ipynb", "‡∏ó‡∏≥ GridSearchCV", "Save reports/cv_results_v3.csv"] },
    { title: "Workshop B: Artifacts v3", steps: ["Evaluate Best Model on Test Set", "Save models/v3/ artifacts", "Compare v2 vs v3"] }
  ],
  exercises: [
    { level: "Easy", title: "Change Splits", description: "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô n_splits ‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏´‡∏£‡∏∑‡∏≠ 10 ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏π‡∏ú‡∏• Mean/Std" },
    { level: "Medium", title: "New Model Family", description: "‡∏•‡∏≠‡∏á‡∏à‡∏π‡∏ô RandomForestClassifier ‡πÅ‡∏ó‡∏ô LogisticRegression" },
    { level: "Challenge", title: "RepeatedCV", description: "‡πÉ‡∏ä‡πâ RepeatedStratifiedKFold ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î" }
  ],
  debugCorner: [
    { problem: "GridSearch ‡∏ä‡πâ‡∏≤", solution: "‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô param_grid ‡∏´‡∏£‡∏∑‡∏≠ n_splits, ‡πÉ‡∏ä‡πâ n_jobs=-1" },
    { problem: "Test score ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ CV", solution: "‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î Overfitting ‡∏Å‡∏±‡∏ö CV ‡∏´‡∏£‡∏∑‡∏≠ Variance ‡∏™‡∏π‡∏á (‡∏î‡∏π Std)" },
    { problem: "Data Leakage", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Test Set ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÉ‡∏ô GridSearchCV" }
  ],
  quiz: [
    { id: 1, question: "‡∏ó‡∏≥‡πÑ‡∏° Test Set ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡∏∞‡∏ï‡∏≠‡∏ô‡∏à‡∏π‡∏ô?", options: ["‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏±‡πâ‡∏ô", "‡∏Å‡∏±‡∏ô‡πÅ‡∏≠‡∏ö‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö/‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏´‡∏•‡∏≠‡∏Å", "GPU ‡∏£‡πâ‡∏≠‡∏ô", "Pandas Error"], correctAnswer: 1, explanation: "‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ Test Set ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á" },
    { id: 2, question: "Cross-Validation ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°?", options: ["‡πÄ‡∏•‡∏Ç‡∏™‡∏∏‡πà‡∏°", "Mean/Std ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Split", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Metrics"], correctAnswer: 1, explanation: "‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ (Stability) ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•" },
    { id: 3, question: "GridSearchCV ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£?", options: ["‡πÇ‡∏´‡∏•‡∏î Data", "‡∏•‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå+‡∏ß‡∏±‡∏î‡∏ú‡∏• CV", "Plot Graph", "API"], correctAnswer: 1, explanation: "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Hyperparameter ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö" },
    { id: 4, question: "‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥ CV ‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡πÑ‡∏´‡∏ô?", options: ["‡∏ó‡∏±‡πâ‡∏á Dataset", "Train Set Only", "Test Set Only", "‡πÑ‡∏°‡πà‡∏ó‡∏≥"], correctAnswer: 1, explanation: "‡∏ó‡∏≥‡∏ö‡∏ô Train ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô Test ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏¢‡∏Å‡πÑ‡∏ß‡πâ‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏≤‡∏Å" },
    { id: 5, question: "cv_results_ ‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ", "‡∏î‡∏π‡∏ú‡∏•‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏∏‡∏Å Params", "‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏´‡∏±‡∏™", "‡πÄ‡∏Å‡πá‡∏ö Model"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤ Parameter ‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£" },
    { id: 6, question: "F1-macro ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö?", options: ["Imbalanced Class", "Regression", "No Target", "Image Only"], correctAnswer: 0, explanation: "‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å Class ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô" },
    { id: 7, question: "‡∏ñ‡πâ‡∏≤ Tuning ‡πÅ‡∏•‡πâ‡∏ß Test ‡πÅ‡∏¢‡πà‡∏•‡∏á?", options: ["‡πÇ‡∏Ñ‡πâ‡∏î‡∏û‡∏±‡∏á", "Overfit ‡∏Å‡∏±‡∏ö CV/Variance ‡∏™‡∏π‡∏á", "‡∏•‡∏¥‡∏Ç‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ú‡∏¥‡∏î", "Docker ‡∏û‡∏±‡∏á"], correctAnswer: 1, explanation: "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏à‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö CV ‡πÄ‡∏Å‡πà‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà Generalize" },
    { id: 8, question: "Grid ‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏µ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏¢‡πà", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ concept ‡∏ó‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Save", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á CV"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏≠‡∏≤‡∏à‡∏Ç‡∏¢‡∏≤‡∏¢ Grid ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏î‡πâ" },
    { id: 9, question: "‡∏ñ‡πâ‡∏≤ CV Mean ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô ‡∏î‡∏π‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡πà‡∏≠?", options: ["‡∏™‡∏µ", "Std (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)", "‡∏ä‡∏∑‡πà‡∏≠", "‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå"], correctAnswer: 1, explanation: "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà Std ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ (‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤)" },
    { id: 10, question: "Week 4 DoD ‡∏Ñ‡∏∑‡∏≠?", options: ["Notebook", "CV+Tuning+Artifacts v3", "UI", "Docker"], correctAnswer: 1, explanation: "‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏π‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏• v3 ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô" }
  ]
};

export const WEEK_5_LESSON_PLAN: LessonPlan = {
  week: 5,
  topic: "Error Analysis + Model v4",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 4", detail: "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô v3: CV + Tuning" },
    { time: "0:10 - 0:25", activity: "Theory: Error Analysis", detail: "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: Data, Feature, ‡∏´‡∏£‡∏∑‡∏≠ Model?" },
    { time: "0:25 - 0:45", activity: "Tools", detail: "Confusion Matrix, Classification Report, Error Table" },
    { time: "0:45 - 1:15", activity: "Live Demo 1", detail: "‡∏™‡∏£‡πâ‡∏≤‡∏á Error Table + ‡∏´‡∏≤ Top Error Patterns" },
    { time: "1:15 - 1:35", activity: "Live Demo 2", detail: "Data-centric Fix: Polynomial Features / New Model" },
    { time: "1:35 - 2:05", activity: "Workshop A", detail: "‡∏ó‡∏≥ Error Analysis Report & Table" },
    { time: "2:05 - 2:40", activity: "Workshop B", detail: "‡∏™‡∏£‡πâ‡∏≤‡∏á v4 (Action from Insight) + Save Artifacts" },
    { time: "2:40 - 2:50", activity: "Compare", detail: "Compare v3 vs v4 Report" },
    { time: "2:50 - 3:00", activity: "Wrap-up & Quiz", detail: "‡∏™‡∏£‡∏∏‡∏õ DoD ‡πÅ‡∏•‡∏∞ Quiz" }
  ],
  contentSummary: [
    { title: "Error Analysis", points: ["‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á (Error Table)", "‡∏´‡∏≤ Pattern: Label ‡∏ú‡∏¥‡∏î? Feature ‡πÑ‡∏°‡πà‡∏û‡∏≠?"] },
    { title: "Data-Centric AI", points: ["‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/Feature ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•", "‡πÄ‡∏û‡∏¥‡πà‡∏° Polynomial Features, ‡πÅ‡∏Å‡πâ Class Weight"] },
    { title: "Confusion Matrix", points: ["‡∏î‡∏π‡∏ß‡πà‡∏≤ Class ‡πÑ‡∏´‡∏ô‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏Å‡∏±‡∏ö Class ‡πÑ‡∏´‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"] }
  ],
  demoScript: [
    { step: "1. Error Table", description: "‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏™‡∏ó‡∏µ‡πà‡∏ó‡∏≤‡∏¢‡∏ú‡∏¥‡∏î", code: "err_df = X_test[y_test != pred].copy()\nerr_df['true'] = y_test\nerr_df['pred'] = pred" },
    { step: "2. Improvement (Poly)", description: "‡πÄ‡∏û‡∏¥‡πà‡∏° PolynomialFeatures", code: "pipe = Pipeline([('poly', PolynomialFeatures(2)), ('scaler', StandardScaler()), ('clf', LogisticRegression())])" },
    { step: "3. Save v4", description: "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• v4 ‡πÅ‡∏•‡∏∞ Metrics", code: "joblib.dump(pipe, 'models/v4/model.joblib')" }
  ],
  workshopSteps: [
    { title: "Workshop A: Analysis", steps: ["‡∏™‡∏£‡πâ‡∏≤‡∏á notebooks/05_error_analysis.ipynb", "Save reports/error_table_v3.csv", "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Insight 5 ‡∏Ç‡πâ‡∏≠"] },
    { title: "Workshop B: Model v4", steps: ["Train v4 based on insight", "Save models/v4/ artifacts", "Compare v3 vs v4"] }
  ],
  exercises: [
    { level: "Easy", title: "Error Type", description: "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå error_type ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (‡πÄ‡∏ä‡πà‡∏ô 'False Positive')" },
    { level: "Medium", title: "Class Weight", description: "‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ class_weight='balanced' ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Recall ‡∏ï‡πà‡∏≥" },
    { level: "Challenge", title: "Hardest Samples", description: "‡∏´‡∏≤‡πÄ‡∏Ñ‡∏™‡∏ó‡∏µ‡πà Confidence ‡∏™‡∏π‡∏á‡πÅ‡∏ï‡πà‡∏ó‡∏≤‡∏¢‡∏ú‡∏¥‡∏î (Miscalibrated)" }
  ],
  debugCorner: [
    { problem: "Poly Features ‡∏ä‡πâ‡∏≤", solution: "‡∏•‡∏î degree ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 2 ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Feature ‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô" },
    { problem: "Score ‡πÅ‡∏¢‡πà‡∏•‡∏á", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Action ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Insight ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (Overfitting?)" },
    { problem: "Encoding Error", solution: "‡πÉ‡∏ä‡πâ UTF-8 ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô/‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô CSV" }
  ],
  quiz: [
    { id: 1, question: "Error Analysis ‡∏ó‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏Ñ‡πâ‡∏î", "‡∏£‡∏π‡πâ‡∏à‡∏∏‡∏î‡∏ú‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏à‡∏∏‡∏î", "‡πÉ‡∏ä‡πâ GPU", "Deploy"], correctAnswer: 1, explanation: "‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á" },
    { id: 2, question: "Confusion Matrix ‡πÅ‡∏ñ‡∏ß‡∏Ñ‡∏∑‡∏≠?", options: ["Predicted", "True Label", "Feature", "Prob"], correctAnswer: 1, explanation: "‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô sklearn ‡πÅ‡∏ñ‡∏ß‡∏Ñ‡∏∑‡∏≠ True Label ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ñ‡∏∑‡∏≠ Predicted" },
    { id: 3, question: "‡∏ñ‡πâ‡∏≤‡∏ó‡∏≤‡∏¢ A ‡πÄ‡∏õ‡πá‡∏ô B ‡∏ö‡πà‡∏≠‡∏¢‡πÜ?", options: ["‡∏î‡∏µ‡∏°‡∏≤‡∏Å", "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏¢‡∏Å A/B ‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å ‡∏î‡∏π Feature", "Dataset ‡∏ú‡∏¥‡∏î", "Deploy ‡πÄ‡∏•‡∏¢"], correctAnswer: 1, explanation: "‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏≤ Feature ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏¢‡∏Å‡∏™‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô" },
    { id: 4, question: "Error Table ‡∏°‡∏µ‡πÑ‡∏ß‡πâ?", options: ["‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà", "‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á", "‡πÅ‡∏ó‡∏ô Metrics", "‡πÅ‡∏ó‡∏ô Model"], correctAnswer: 1, explanation: "‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤" },
    { id: 5, question: "Data-centric ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á?", options: ["‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•", "‡πÄ‡∏ô‡πâ‡∏ô‡πÅ‡∏Å‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/Feature", "‡πÄ‡∏û‡∏¥‡πà‡∏° GPU", "Docker"], correctAnswer: 1, explanation: "‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•" },
    { id: 6, question: "Confidence ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£?", options: ["‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Class", "‡∏´‡∏≤‡∏ú‡∏¥‡∏î‡πÅ‡∏ö‡∏ö‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (Hard Error)", "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Test"], correctAnswer: 1, explanation: "‡∏ä‡πà‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏Ñ‡∏™‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏• '‡∏´‡∏•‡∏á‡∏ú‡∏¥‡∏î' ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á" },
    { id: 7, question: "PolynomialFeatures ‡∏ú‡∏•‡∏Ñ‡∏∑‡∏≠?", options: ["‡∏•‡∏î Feature", "‡πÄ‡∏û‡∏¥‡πà‡∏° Feature ‡πÄ‡∏ä‡∏¥‡∏á‡∏ú‡∏™‡∏° (Boundary ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô)", "Categorical", "PII"], correctAnswer: 1, explanation: "‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ Linear Model ‡∏à‡∏±‡∏ö Pattern ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡πÑ‡∏î‡πâ" },
    { id: 8, question: "‡∏ñ‡πâ‡∏≤ v4 ‡πÅ‡∏¢‡πà‡∏•‡∏á‡∏ó‡∏≥‡πÑ‡∏á?", options: ["‡∏•‡∏ö Repo", "‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏î‡∏π Analysis ‡∏ß‡πà‡∏≤‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏à‡∏∏‡∏î‡πÑ‡∏´‡∏°", "Degree 5", "Deploy"], correctAnswer: 1, explanation: "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ã‡πâ‡∏≥ (Iterate) ‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á ML" },
    { id: 9, question: "Hard Errors ‡∏Ñ‡∏∑‡∏≠?", options: ["‡∏ú‡∏¥‡∏î Confidence ‡∏ï‡πà‡∏≥", "‡∏ú‡∏¥‡∏î Confidence ‡∏™‡∏π‡∏á", "‡∏ñ‡∏π‡∏Å‡πÄ‡∏™‡∏°‡∏≠", "‡πÑ‡∏°‡πà‡∏°‡∏µ"], correctAnswer: 1, explanation: "‡∏ú‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏∑‡∏≠‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î" },
    { id: 10, question: "Week 5 DoD ‡∏Ñ‡∏∑‡∏≠?", options: ["Model v4", "Error Analysis + Action + Artifacts v4", "UI", "Docker"], correctAnswer: 1, explanation: "‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ" }
  ]
};

export const WEEK_6_LESSON_PLAN: LessonPlan = {
  week: 6,
  topic: "Split + Threshold + Calibration (v5)",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 5", detail: "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô v4 (Error Analysis)" },
    { time: "0:10 - 0:30", activity: "Theory: Train/Val/Test", detail: "Split 3 ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏ö‡∏ö‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£ (70/15/15) + Roles" },
    { time: "0:30 - 0:45", activity: "Leakage Checklist", detail: "10 ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á (Preprocessing, Tuning, Features)" },
    { time: "0:45 - 1:10", activity: "Theory: Threshold", detail: "Probability -> Decision (Precision vs Recall Tradeoff)" },
    { time: "1:10 - 1:35", activity: "Live Demo 1", detail: "3-way Split + Baseline v5" },
    { time: "1:35 - 2:05", activity: "Workshop A", detail: "Split Data & Leakage Checklist" },
    { time: "2:05 - 2:25", activity: "Live Demo 2", detail: "Threshold Selection from Val" },
    { time: "2:25 - 2:40", activity: "Live Demo 3", detail: "Calibration Basics" },
    { time: "2:40 - 2:55", activity: "Workshop B", detail: "Threshold Policy, Save v5 Artifacts, Docs" },
    { time: "2:55 - 3:00", activity: "Wrap-up & Quiz", detail: "‡∏™‡∏£‡∏∏‡∏õ DoD ‡πÅ‡∏•‡∏∞ Quiz" }
  ],
  contentSummary: [
    { title: "Train/Val/Test", points: ["Train: ‡∏ù‡∏∂‡∏Å", "Val: ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Threshold", "Test: ‡∏ß‡∏±‡∏î‡∏ú‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡∏∞)"] },
    { title: "Thresholding", points: ["‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (Default 0.5) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Precision/Recall", "‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö Business Logic (Cost of False Pos/Neg)"] },
    { title: "Calibration", points: ["‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ Probability ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á (‡πÄ‡∏ä‡πà‡∏ô 0.8 ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏ñ‡∏π‡∏Å 80% ‡∏à‡∏£‡∏¥‡∏á‡πÜ)"] }
  ],
  demoScript: [
    { step: "1. 3-Way Split", description: "‡πÅ‡∏ö‡πà‡∏á Train/Val/Test", code: "X_temp, X_test, ... = train_test_split(..., test_size=0.15)\nX_train, X_val, ... = train_test_split(X_temp, ..., test_size=0.1765)" },
    { step: "2. Threshold Sweep", description: "‡∏´‡∏≤ Best Threshold ‡∏ö‡∏ô Val", code: "for t in thresholds: f1_score(y_val, proba_val >= t)" },
    { step: "3. Save Policy", description: "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Threshold ‡∏•‡∏á Meta", code: "meta = {'threshold': best_t, ...}" }
  ],
  workshopSteps: [
    { title: "Workshop A: Setup", steps: ["‡∏™‡∏£‡πâ‡∏≤‡∏á notebooks/06_split_threshold.ipynb", "‡∏ó‡∏≥ 3-way split", "Checklist Data Leakage"] },
    { title: "Workshop B: Policy & v5", steps: ["‡∏´‡∏≤ Best Threshold ‡∏à‡∏≤‡∏Å Val", "Save models/v5/ artifacts", "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô threshold_policy_v5.md"] }
  ],
  exercises: [
    { level: "Easy", title: "Alt Policy", description: "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Threshold ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Å‡∏ì‡∏ë‡πå Precision >= 0.9" },
    { level: "Medium", title: "Target Change", description: "‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Target ‡πÄ‡∏õ‡πá‡∏ô Class ‡∏≠‡∏∑‡πà‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥ Policy ‡πÉ‡∏´‡∏°‡πà" },
    { level: "Challenge", title: "Calibration Eval", description: "‡∏û‡∏•‡πá‡∏≠‡∏ï Reliability Diagram ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Brier Score" }
  ],
  debugCorner: [
    { problem: "Precision Undefined", solution: "‡πÉ‡∏™‡πà zero_division=0 ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Threshold ‡∏™‡∏π‡∏á‡πÑ‡∏õ‡∏à‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ Positive" },
    { problem: "Class Imbalance", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Stratify ‡∏ï‡∏≠‡∏ô Split" },
    { problem: "Leakage", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Threshold ‡∏°‡∏≤‡∏à‡∏≤‡∏Å Val ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô" }
  ],
  quiz: [
    { id: 1, question: "Validation Set ‡∏°‡∏µ‡πÑ‡∏ß‡πâ?", options: ["‡πÄ‡∏ó‡∏£‡∏ô", "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•/Threshold", "‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á", "‡πÄ‡∏Å‡πá‡∏ö PII"], correctAnswer: 1, explanation: "‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ Overfit ‡∏Å‡∏±‡∏ö Test Set" },
    { id: 2, question: "Test Set ‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô‡πÑ‡∏´‡∏ô?", options: ["‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á", "‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡∏à‡∏ö", "‡∏Å‡πà‡∏≠‡∏ô Train", "‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ"], correctAnswer: 1, explanation: "‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∏‡∏ï‡∏¥‡∏ò‡∏£‡∏£‡∏°" },
    { id: 3, question: "Data Leakage ‡∏Ñ‡∏∑‡∏≠?", options: ["‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏´‡∏•‡∏∏‡∏î‡πÄ‡∏Ç‡πâ‡∏≤ Train", "‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏ß‡∏¢", "GPU"], correctAnswer: 1, explanation: "‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡∏µ‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ" },
    { id: 4, question: "Threshold ‡∏Ñ‡∏∑‡∏≠?", options: ["‡∏ä‡∏∑‡πà‡∏≠ Dataset", "‡∏Ñ‡πà‡∏≤‡∏à‡∏∏‡∏î‡∏ï‡∏±‡∏î Probability", "Learning Rate", "Seed"], correctAnswer: 1, explanation: "‡∏à‡∏∏‡∏î‡∏ï‡∏±‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à Class (‡πÄ‡∏ä‡πà‡∏ô >= 0.6 ‡πÄ‡∏õ‡πá‡∏ô Positive)" },
    { id: 5, question: "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Threshold ‡∏≠‡∏¥‡∏á‡∏ä‡∏∏‡∏î‡πÑ‡∏´‡∏ô?", options: ["Train", "Val", "Test", "All"], correctAnswer: 1, explanation: "‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¥‡∏á Validation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ Bias (Train) ‡∏´‡∏£‡∏∑‡∏≠ Cheat (Test)" },
    { id: 6, question: "Calibration ‡∏ä‡πà‡∏ß‡∏¢?", options: ["‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡πá‡∏ß", "Prob ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Split", "Docker"], correctAnswer: 1, explanation: "‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ Probability ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏£‡∏¥‡∏á" },
    { id: 7, question: "‡∏ñ‡πâ‡∏≤ FN ‡πÅ‡∏û‡∏á‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡πÑ‡∏á?", options: ["‡πÄ‡∏û‡∏¥‡πà‡∏° Threshold", "‡∏•‡∏î Threshold", "‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ", "‡πÉ‡∏ä‡πâ Test"], correctAnswer: 1, explanation: "‡∏•‡∏î Threshold ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö Positive ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô (‡∏¢‡∏≠‡∏° FP ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)" },
    { id: 8, question: "Fix Random State ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á", "‡∏ú‡∏•‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ", "Pipeline ‡∏´‡∏≤‡∏¢", "No missing"], correctAnswer: 1, explanation: "Reproducibility ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡πÉ‡∏ô‡∏á‡∏≤‡∏ô Science" },
    { id: 9, question: "‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏ô Meta?", options: ["Version", "Threshold", "Metrics", "Password"], correctAnswer: 3, explanation: "Secrets ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö (Environment Variables)" },
    { id: 10, question: "Week 6 DoD?", options: ["Model Only", "Split+Threshold+Artifacts v5", "UI", "Docker"], correctAnswer: 1, explanation: "‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Model ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° Deploy ‡∏û‡∏£‡πâ‡∏≠‡∏° Policy ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à" }
  ]
};

export const WEEK_7_LESSON_PLAN: LessonPlan = {
  week: 7,
  topic: "FastAPI Deployment",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 6", detail: "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô v5: Ready for Deploy" },
    { time: "0:10 - 0:25", activity: "Theory: API Basics", detail: "API Contract, /health, /predict, Security Check" },
    { time: "0:25 - 0:40", activity: "FastAPI Architecture", detail: "Structure: main.py, schemas.py, config.py" },
    { time: "0:40 - 1:10", activity: "Live Demo 1", detail: "Create /health & Load Model Artifacts" },
    { time: "1:10 - 1:40", activity: "Live Demo 2", detail: "Create /predict + Validation + Contract Check" },
    { time: "1:40 - 2:05", activity: "Workshop A", detail: "Implement API & Swagger UI Test" },
    { time: "2:05 - 2:25", activity: "Live Demo 3", detail: "Safe Logging & Error Handling" },
    { time: "2:25 - 2:50", activity: "Workshop B", detail: "Write Tests (pytest) 5 Cases" },
    { time: "2:50 - 3:00", activity: "Wrap-up & Quiz", detail: "‡∏™‡∏£‡∏∏‡∏õ DoD ‡πÅ‡∏•‡∏∞ Quiz" }
  ],
  contentSummary: [
    { title: "REST API", points: ["‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡πÉ‡∏´‡πâ Software ‡∏≠‡∏∑‡πà‡∏ô‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö Model", "/health: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞, /predict: ‡∏Ç‡∏≠‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"] },
    { title: "Input Validation", points: ["Pydantic: ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏¢‡∏∞‡∏Å‡πà‡∏≠‡∏ô‡∏ñ‡∏∂‡∏á Model", "Feature Contract: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠/‡∏ä‡∏ô‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á"] },
    { title: "Safe Logging", points: ["Log Meta (Time, ID, Status) ‡πÅ‡∏ï‡πà‡∏´‡πâ‡∏≤‡∏° Log Raw Input (Privacy)"] }
  ],
  demoScript: [
    { step: "1. Config & Load", description: "‡πÇ‡∏´‡∏•‡∏î Model/Meta ‡∏à‡∏≤‡∏Å config.py", code: "model = joblib.load(MODEL_PATH)\nfeatures = json.load(FEATURES_PATH)" },
    { step: "2. Schema", description: "‡∏ô‡∏¥‡∏¢‡∏≤‡∏° Input/Output ‡∏î‡πâ‡∏ß‡∏¢ Pydantic", code: "class PredictRequest(BaseModel):\n features: Dict[str, float]" },
    { step: "3. Predict Endpoint", description: "‡∏™‡∏£‡πâ‡∏≤‡∏á Route /predict", code: "@app.post('/predict')\ndef predict(req): ..." }
  ],
  workshopSteps: [
    { title: "Workshop A: Build API", steps: ["Setup Folder Structure", "Implement main.py/schemas.py", "Run uvicorn & Check Swagger"] },
    { title: "Workshop B: Tests", steps: ["Create tests/test_api.py", "Test Health, Predict, Error Cases", "Run pytest"] }
  ],
  exercises: [
    { level: "Easy", title: "Info Endpoint", description: "‡πÄ‡∏û‡∏¥‡πà‡∏° GET /model-info ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ Version/Features" },
    { level: "Medium", title: "Request ID", description: "‡πÄ‡∏û‡∏¥‡πà‡∏° X-Request-ID Header ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Traceability" },
    { level: "Challenge", title: "Rate Limit", description: "‡∏ó‡∏≥ Simple Rate Limiting (In-memory)" }
  ],
  debugCorner: [
    { problem: "ModuleNotFoundError", solution: "Run uvicorn ‡∏à‡∏≤‡∏Å Root Folder (python -m uvicorn ...)" },
    { problem: "Path Error", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö BASE_DIR ‡πÉ‡∏ô config.py" },
    { problem: "422 Validation Error", solution: "‡πÄ‡∏ä‡πá‡∏Ñ JSON Body ‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á Schema (‡∏°‡∏µ key 'features' ‡πÑ‡∏´‡∏°)" }
  ],
  quiz: [
    { id: 1, question: "Endpoint ‡πÉ‡∏î‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Health Check?", options: ["/predict", "/health", "/train", "/data"], correctAnswer: 1, explanation: "‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≤‡∏Å‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£" },
    { id: 2, question: "Validation ‡∏°‡∏µ‡πÑ‡∏ß‡πâ?", options: ["‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏±‡πâ‡∏ô", "‡∏Å‡∏±‡∏ô Input ‡∏û‡∏±‡∏á/Runtime Error", "Accuracy", "Docker"], correctAnswer: 1, explanation: "‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏¢‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î" },
    { id: 3, question: "Feature Contract ‡∏Ñ‡∏∑‡∏≠?", options: ["‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô", "‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠/‡∏•‡∏≥‡∏î‡∏±‡∏ö Feature ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á", "Dataset", "Threshold"], correctAnswer: 1, explanation: "‡∏Ç‡πâ‡∏≠‡∏ï‡∏Å‡∏•‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á API ‡πÅ‡∏•‡∏∞ Model ‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô" },
    { id: 4, question: "‡∏™‡∏¥‡πà‡∏á‡πÉ‡∏î '‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£' Log?", options: ["Req ID", "Latency", "Model Ver", "Raw Input"], correctAnswer: 3, explanation: "‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î Privacy/PDPA" },
    { id: 5, question: "/predict ‡∏Ñ‡∏ß‡∏£‡∏Ñ‡∏∑‡∏ô‡∏≠‡∏∞‡πÑ‡∏£?", options: ["‡∏£‡∏π‡∏õ", "Pred + Proba + Meta", "Graph", "CSV"], correctAnswer: 1, explanation: "‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à" },
    { id: 6, question: "Enforce Feature Order ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡πÄ‡∏£‡πá‡∏ß", "‡πÅ‡∏°‡∏õ‡∏Ñ‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ñ‡∏π‡∏Å", "‡∏™‡∏ß‡∏¢", "Test ‡∏ú‡πà‡∏≤‡∏ô"], correctAnswer: 1, explanation: "Scikit-learn model ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏ä‡∏∑‡πà‡∏≠ Column (‡πÉ‡∏ô array) ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å" },
    { id: 7, question: "‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏ 422 ‡∏Ñ‡∏∑‡∏≠?", options: ["Model ‡πÄ‡∏™‡∏µ‡∏¢", "JSON ‡∏ú‡∏¥‡∏î Schema", "Feature ‡πÄ‡∏¢‡∏≠‡∏∞", "Pandas"], correctAnswer: 1, explanation: "Pydantic ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î" },
    { id: 8, question: "Happy Path ‡∏Ñ‡∏∑‡∏≠?", options: ["‡∏™‡πà‡∏á‡∏Ç‡∏≤‡∏î", "‡∏™‡πà‡∏á‡∏Ñ‡∏£‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á", "‡∏™‡πà‡∏á‡πÄ‡∏Å‡∏¥‡∏ô", "‡∏™‡πà‡∏á String"], correctAnswer: 1, explanation: "‡∏Å‡∏£‡∏ì‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à" },
    { id: 9, question: "‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á Test?", options: ["UI ‡∏™‡∏ß‡∏¢", "‡∏Å‡∏±‡∏ô Regression/‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Å‡πà‡∏≠‡∏ô Deploy", "F1", "Data"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏±‡∏á" },
    { id: 10, question: "Week 7 DoD?", options: ["v5", "API Running + Tests", "Docker", "Streamlit"], correctAnswer: 1, explanation: "‡∏°‡∏µ API ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö" }
  ]
};

export const WEEK_8_LESSON_PLAN: LessonPlan = {
  week: 8,
  topic: "Streamlit UI & Demo",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 7", detail: "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô API (/health, /predict)" },
    { time: "0:10 - 0:25", activity: "Theory: UI/UX for ML", detail: "Flow: Validate -> Call -> Handle Error -> Show Result" },
    { time: "0:25 - 0:50", activity: "Live Demo 1", detail: "Streamlit Skeleton & API Status Check" },
    { time: "0:50 - 1:20", activity: "Live Demo 2", detail: "Auto-generate Form from features.json" },
    { time: "1:20 - 1:45", activity: "Live Demo 3", detail: "Call /predict & Handle States (Loading/Error)" },
    { time: "1:45 - 2:10", activity: "Workshop A", detail: "Build UI connecting to API" },
    { time: "2:10 - 2:35", activity: "Live Demo 4", detail: "UX Polish (Presets, Reset, Logs)" },
    { time: "2:35 - 2:50", activity: "Workshop B", detail: "Demo Pack (Usage Docs + Checklist)" },
    { time: "2:50 - 3:00", activity: "Wrap-up & Final Quiz", detail: "‡∏à‡∏ö Class" }
  ],
  contentSummary: [
    { title: "UI for ML", points: ["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô: ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô: API ‡∏•‡πà‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡πâ‡∏≤‡∏á", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠: ‡πÅ‡∏™‡∏î‡∏á Model Version/Threshold"] },
    { title: "Dynamic Form", points: ["‡∏™‡∏£‡πâ‡∏≤‡∏á Input ‡∏ï‡∏≤‡∏° features.json ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥", "‡∏•‡∏î‡∏á‡∏≤‡∏ô‡πÅ‡∏Å‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô"] },
    { title: "Demo Ready", points: ["‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Script, Screenshots, ‡πÅ‡∏•‡∏∞ Video ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Portfolio"] }
  ],
  demoScript: [
    { step: "1. UI Skeleton", description: "‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏•‡∏∞ Sidebar", code: "st.title('AI Demo')\nif st.button('Check API'): ..." },
    { step: "2. Dynamic Form", description: "‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏™‡∏£‡πâ‡∏≤‡∏á Input Widget", code: "inputs = {}\nfor f in features: inputs[f] = st.number_input(f)" },
    { step: "3. API Call", description: "‡∏™‡πà‡∏á Request ‡πÑ‡∏õ API", code: "r = requests.post(URL, json={'features': inputs})" }
  ],
  workshopSteps: [
    { title: "Workshop A: UI Build", steps: ["Create ui/app.py & config.py", "Connect to Local API", "Test Error States"] },
    { title: "Workshop B: Demo Pack", steps: ["Create docs/ui_usage.md", "Create docs/demo_checklist.md", "Record Short Demo"] }
  ],
  exercises: [
    { level: "Easy", title: "Example Button", description: "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏∏‡πà‡∏° 'Load Example' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥" },
    { level: "Medium", title: "Probability Graph", description: "‡πÄ‡∏û‡∏¥‡πà‡∏° Bar Chart ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤ Probability Comparison" },
    { level: "Challenge", title: "Batch Predict", description: "‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö File Upload (CSV) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ñ‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô" }
  ],
  debugCorner: [
    { problem: "FileNotFound features.json", solution: "‡∏£‡∏±‡∏ô Streamlit ‡∏à‡∏≤‡∏Å Root Directory" },
    { problem: "ConnectionError", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ API (Uvicorn) ‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà" },
    { problem: "API 400 Error", solution: "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Payload ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏ß‡πà‡∏≤ Key ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö API Schema ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà" }
  ],
  quiz: [
    { id: 1, question: "UI ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Model ‡∏ú‡πà‡∏≤‡∏ô?", options: ["Joblib", "FastAPI", "SQL", "GPU"], correctAnswer: 1, explanation: "Frontend (UI) ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö Backend (Model) ‡∏ú‡πà‡∏≤‡∏ô REST API" },
    { id: 2, question: "‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Loading?", options: ["‡∏™‡∏ß‡∏¢", "UX: ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà", "F1", "CORS"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏Ñ‡πâ‡∏≤‡∏á" },
    { id: 3, question: "‡∏ñ‡πâ‡∏≤ API ‡∏•‡πà‡∏°?", options: ["‡πÄ‡∏á‡∏µ‡∏¢‡∏ö", "‡πÅ‡∏à‡πâ‡∏á Error Message", "‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°", "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Model"], correctAnswer: 1, explanation: "Fail Gracefully: ‡πÅ‡∏à‡πâ‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏≤‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤" },
    { id: 4, question: "Form ‡∏à‡∏≤‡∏Å features.json ‡∏î‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?", options: ["‡∏¢‡∏≤‡∏ß", "‡∏•‡∏î‡∏ú‡∏¥‡∏î/‡∏ï‡∏£‡∏á Contract", "PII", "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°"], correctAnswer: 1, explanation: "‡∏ó‡∏≥‡πÉ‡∏´‡πâ UI ‡πÅ‡∏•‡∏∞ API ‡∏ã‡∏¥‡∏á‡∏Ñ‡πå‡∏Å‡∏±‡∏ô‡πÄ‡∏™‡∏°‡∏≠ ‡∏•‡∏î Human Error" },
    { id: 5, question: "‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£ Log ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏ô UI?", options: ["Latency", "Status", "Event", "Raw Input"], correctAnswer: 3, explanation: "Privacy Concern" },
    { id: 6, question: "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠?", options: ["‡∏™‡∏µ", "Version/Threshold", "‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏π", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏ü‡∏•‡πå"], correctAnswer: 1, explanation: "Metadata ‡∏ä‡πà‡∏ß‡∏¢‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå" },
    { id: 7, question: "‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏£‡∏±‡∏ô UI?", options: ["uvicorn", "streamlit run app.py", "python app.py", "node"], correctAnswer: 1, explanation: "Streamlit CLI command" },
    { id: 8, question: "API 400 ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á?", options: ["‡∏õ‡∏Å‡∏ï‡∏¥", "Client Error (Payload ‡∏ú‡∏¥‡∏î)", "Server Error", "Success"], correctAnswer: 1, explanation: "Bad Request: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á" },
    { id: 9, question: "Demo Checklist ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["‡πÉ‡∏´‡∏ç‡πà", "Portfolio Ready", "‡πÅ‡∏°‡πà‡∏ô", "‡πÄ‡∏£‡πá‡∏ß"], correctAnswer: 1, explanation: "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ Material ‡∏Ñ‡∏£‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠‡∏ú‡∏•‡∏á‡∏≤‡∏ô" },
    { id: 10, question: "Week 8 DoD?", options: ["UI Only", "UI + API + Docs", "Docker", "Cloud"], correctAnswer: 1, explanation: "‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£ (Frontend + Backend) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£" }
  ]
};

export const WEEK_9_LESSON_PLAN: LessonPlan = {
  week: 9,
  topic: "Dockerize API + UI + Compose",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 8", detail: "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô: UI calling API locally. Goal: Run anywhere with Docker." },
    { time: "0:10 - 0:30", activity: "Theory: Docker Basics", detail: "Image vs Container, Volume, Compose, Dockerfile syntax" },
    { time: "0:30 - 0:45", activity: "Project Prep", detail: "Structure files, .dockerignore, Environment Variables" },
    { time: "0:45 - 1:10", activity: "Live Demo 1", detail: "Dockerfile for FastAPI (API Service)" },
    { time: "1:10 - 1:35", activity: "Live Demo 2", detail: "Dockerfile for Streamlit (UI Service)" },
    { time: "1:35 - 2:05", activity: "Workshop A", detail: "Build & Run API/UI containers separately" },
    { time: "2:05 - 2:30", activity: "Live Demo 3", detail: "Docker Compose: Orchestrating both services + Healthcheck" },
    { time: "2:30 - 2:50", activity: "Workshop B", detail: "Create docker-compose.yml, Runbook, Checklist" },
    { time: "2:50 - 3:00", activity: "Wrap-up & Quiz", detail: "Final check & Quiz" }
  ],
  contentSummary: [
    { title: "Docker", points: ["Standardizes environments (runs the same on your laptop and cloud).", "Container: Running instance of an Image."] },
    { title: "Docker Compose", points: ["Manage multi-container apps (API + UI).", "Handles networking and service discovery (http://api:8000)."] },
    { title: "Healthcheck", points: ["Ensures API is ready before UI starts (depends_on)."] }
  ],
  demoScript: [
    { step: "1. Dockerfile.api", description: "Blueprint for API", code: "FROM python:3.10-slim\nCOPY . .\nCMD ['uvicorn', 'api.main:app', '--host', '0.0.0.0']" },
    { step: "2. Dockerfile.ui", description: "Blueprint for UI", code: "FROM python:3.10-slim\nCMD ['streamlit', 'run', 'ui/app.py']" },
    { step: "3. docker-compose.yml", description: "Orchestration config", code: "services:\n  api:\n    build: .\n  ui:\n    build: .\n    depends_on: [api]" }
  ],
  workshopSteps: [
    { title: "Workshop A: Containers", steps: ["Create .dockerignore", "Build API Image", "Run API Container", "Build & Run UI Container"] },
    { title: "Workshop B: Compose & Docs", steps: ["Create docker-compose.yml", "Run 'docker compose up'", "Write docs/runbook.md"] }
  ],
  exercises: [
    { level: "Easy", title: "Readme Update", description: "Add Docker commands (build, up, down) to README.md" },
    { level: "Medium", title: "Restart Policy", description: "Add 'restart: unless-stopped' to compose file" },
    { level: "Challenge", title: "Optimization", description: "Reduce image size using multi-stage builds or specific requirements files" }
  ],
  debugCorner: [
    { problem: "Daemon not running", solution: "Start Docker Desktop application" },
    { problem: "Port conflict", solution: "Change host port in compose (e.g., 8001:8000)" },
    { problem: "UI can't reach API", solution: "Use service name (http://api:8000), NOT localhost" }
  ],
  quiz: [
    { id: 1, question: "Docker Image ‡∏Ñ‡∏∑‡∏≠?", options: ["‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà", "‡πÅ‡∏°‡πà‡∏û‡∏¥‡∏°‡∏û‡πå (Blueprint)", "CSV", "Healthcheck"], correctAnswer: 1, explanation: "Image ‡∏Ñ‡∏∑‡∏≠‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á Container" },
    { id: 2, question: "Container ‡∏Ñ‡∏∑‡∏≠?", options: ["Config", "Instance ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏à‡∏≤‡∏Å Image", "Folder", "Package"], correctAnswer: 1, explanation: "‡∏Ñ‡∏∑‡∏≠ Environment ‡∏ó‡∏µ‡πà‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á" },
    { id: 3, question: "Docker Compose ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["Model ‡πÅ‡∏°‡πà‡∏ô", "‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢ Service ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î", "No Logs"], correctAnswer: 1, explanation: "Orchestration tool ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Multi-container applications" },
    { id: 4, question: "UI ‡πÉ‡∏ô Container ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏ú‡πà‡∏≤‡∏ô?", options: ["localhost", "Service Name (http://api:8000)", "127.0.0.1", "0.0.0.0"], correctAnswer: 1, explanation: "‡πÉ‡∏ô Docker Network ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡πà‡∏≤‡∏ô‡∏ä‡∏∑‡πà‡∏≠ Service" },
    { id: 5, question: "Healthcheck ‡πÄ‡∏û‡∏∑‡πà‡∏≠?", options: ["Build ‡πÄ‡∏£‡πá‡∏ß", "‡∏£‡∏≠ Service ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏∑‡πà‡∏ô", "UI ‡∏™‡∏ß‡∏¢", "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Port"], correctAnswer: 1, explanation: "‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô UI ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà API ‡∏à‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£" },
    { id: 6, question: ".dockerignore ‡∏ä‡πà‡∏ß‡∏¢?", options: ["‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î", "‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏¢‡∏∞/Build ‡πÄ‡∏£‡πá‡∏ß/‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢", "Threshold", "F1"], correctAnswer: 1, explanation: "‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡πÄ‡∏ä‡πà‡∏ô .env, venv) ‡∏´‡∏•‡∏∏‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Image" },
    { id: 7, question: "‡∏ñ‡πâ‡∏≤ Port 8000 ‡∏ä‡∏ô?", options: ["‡∏•‡∏ö Docker", "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Port Mapping", "‡πÄ‡∏û‡∏¥‡πà‡∏° Degree", "‡πÅ‡∏Å‡πâ Meta"], correctAnswer: 1, explanation: "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Port ‡∏ù‡∏±‡πà‡∏á Host ‡πÉ‡∏ô docker-compose.yml" },
    { id: 8, question: "‡∏ó‡∏≥‡πÑ‡∏°‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ localhost ‡πÉ‡∏ô Container?", options: ["‡πÄ‡∏ô‡πá‡∏ï‡∏ä‡πâ‡∏≤", "‡∏°‡∏±‡∏ô‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏ï‡∏±‡∏ß Container ‡πÄ‡∏≠‡∏á", "FastAPI ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö", "Compose ‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö"], correctAnswer: 1, explanation: "Localhost ‡πÉ‡∏ô Container ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ñ‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏°‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Host ‡∏´‡∏£‡∏∑‡∏≠ Service ‡∏≠‡∏∑‡πà‡∏ô" },
    { id: 9, question: "‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏£‡∏±‡∏ô Compose?", options: ["docker run", "docker compose up --build", "pip install", "uvicorn"], correctAnswer: 1, explanation: "Build ‡πÅ‡∏•‡∏∞ Start services ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô yml" },
    { id: 10, question: "Week 9 DoD?", options: ["Dockerfile", "Compose Up + UI Predict Success", "Cloud", "Drift"], correctAnswer: 1, explanation: "‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß" }
  ]
};

export const WEEK_10_LESSON_PLAN: LessonPlan = {
  week: 10,
  topic: "Cloud Deployment & CI/CD",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 9", detail: "Reviewed Docker (Local). Goal: Deploy to Cloud so anyone can use it." },
    { time: "0:10 - 0:30", activity: "Theory: Cloud & Secrets", detail: "Cloud PaaS (Streamlit Cloud), Secrets Management (API Keys)" },
    { time: "0:30 - 0:45", activity: "Monitoring Basics", detail: "Uptime checks & Error logging principles" },
    { time: "0:45 - 1:15", activity: "Live Demo 1", detail: "Deploying to Streamlit Cloud (Reqs, Secrets)" },
    { time: "1:15 - 1:40", activity: "Live Demo 2", detail: "Basic Monitoring (App health)" },
    { time: "1:40 - 2:10", activity: "Workshop A", detail: "Deploy Student Apps to Cloud" },
    { time: "2:10 - 2:35", activity: "Live Demo 3", detail: "CI/CD Basics (GitHub Actions for Tests)" },
    { time: "2:35 - 2:55", activity: "Workshop B", detail: "Add CI workflow & Verify Deployment" },
    { time: "2:55 - 3:00", activity: "Wrap-up & Quiz", detail: "Final check & Quiz" }
  ],
  contentSummary: [
    { title: "Cloud Deployment", points: ["Accessible URL for users.", "Scalable infrastructure (managed by provider)."] },
    { title: "Secrets Management", points: ["NEVER commit .env files.", "Use Cloud dashboard to set Environment Variables."] },
    { title: "CI/CD", points: ["Continuous Integration: Run tests automatically on push.", "Prevents broken code from reaching production."] }
  ],
  demoScript: [
    { step: "1. Prepare Repo", description: "Clean requirements.txt", code: "pip freeze > requirements.txt # Ensure only needed libs" },
    { step: "2. Secrets Config", description: "Streamlit Secrets (Local vs Cloud)", code: "# .streamlit/secrets.toml (Local)\napi_key = 'xyz'" },
    { step: "3. GitHub Action", description: "Simple Test Workflow", code: "name: CI\non: [push]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps: ... run pytest" }
  ],
  workshopSteps: [
    { title: "Workshop A: Cloud Deploy", steps: ["Push code to GitHub", "Connect Streamlit Cloud", "Add Secrets in Dashboard", "Verify Live URL"] },
    { title: "Workshop B: CI/CD", steps: ["Create .github/workflows/main.yml", "Push change to trigger CI", "Check Action Status"] }
  ],
  exercises: [
    { level: "Easy", title: "Badge", description: "Add 'Streamlit App' and 'CI Passing' badges to README" },
    { level: "Medium", title: "Fail Test", description: "Intentionally break a test and see CI fail" },
    { level: "Challenge", title: "Pre-commit", description: "Setup pre-commit hook to run tests locally before push" }
  ],
  debugCorner: [
    { problem: "ModuleNotFound on Cloud", solution: "Ensure all libraries are in requirements.txt" },
    { problem: "Secrets missing", solution: "Add secrets in Streamlit Cloud Dashboard (Advanced Settings)" },
    { problem: "CI Failed", solution: "Check Action logs, ensure pytest passes locally" }
  ],
  quiz: [
    { id: 1, question: "Why deploy to Cloud?", options: ["Run on my laptop", "Accessible to anyone via URL", "No internet needed", "Cheaper than free"], correctAnswer: 1, explanation: "Cloud hosting makes your application accessible over the internet." },
    { id: 2, question: "Where do API Keys go?", options: ["In code", "In GitHub Repo", "Secrets Management / Env Vars", "README"], correctAnswer: 2, explanation: "Never expose secrets in code or version control. Use environment variables." },
    { id: 3, question: "CI stands for?", options: ["Cloud Integration", "Continuous Integration", "Code Inspection", "Cyber Intelligence"], correctAnswer: 1, explanation: "Continuous Integration automates merging and testing code." },
    { id: 4, question: "What file lists dependencies?", options: ["package.json", "requirements.txt", "docker-compose.yml", "main.py"], correctAnswer: 1, explanation: "Standard Python dependency file." },
    { id: 5, question: "If CI fails, you should?", options: ["Deploy anyway", "Fix the code/test", "Delete the test", "Ignore it"], correctAnswer: 1, explanation: "CI protects production; fix the issue before proceeding." },
    { id: 6, question: "Streamlit Cloud connects to?", options: ["Your Hard Drive", "GitHub Repository", "Google Drive", "USB Stick"], correctAnswer: 1, explanation: "It pulls code directly from your GitHub repo." },
    { id: 7, question: ".gitignore is for?", options: ["Important files", "Files to EXCLUDE from git (like secrets)", "Documentation", "Images"], correctAnswer: 1, explanation: "Prevents tracking of sensitive or unnecessary files." },
    { id: 8, question: "GitHub Actions is used for?", options: ["Social Media", "Automating workflows (CI/CD)", "Chatting", "Hosting DB"], correctAnswer: 1, explanation: "Automation platform for build, test, and deployment pipelines." },
    { id: 9, question: "Monitoring helps detect?", options: ["New features", "Downtime & Errors", "More users", "Better UI"], correctAnswer: 1, explanation: "Keeps track of application health and issues." },
    { id: 10, question: "Week 10 DoD?", options: ["Local Docker", "Live Cloud URL + CI Setup", "Design", "Concept"], correctAnswer: 1, explanation: "A deployed, automated, and running application." }
  ]
};

export const WEEK_11_LESSON_PLAN: LessonPlan = {
  week: 11,
  topic: "Monitoring & Basic MLOps",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap Week 10", detail: "Deployed to Cloud. Now ensure it stays healthy." },
    { time: "0:10 - 0:30", activity: "Theory: Monitoring 101", detail: "Logs vs Metrics vs Alerts. Why monitoring is crucial." },
    { time: "0:30 - 0:45", activity: "Privacy Logging", detail: "What to log vs What NOT to log (PII, Raw Data)." },
    { time: "0:45 - 1:10", activity: "Live Demo 1", detail: "Implement Structured Logging (JSONL) in FastAPI" },
    { time: "1:10 - 1:35", activity: "Live Demo 2", detail: "Metrics Aggregation Script (Pandas)" },
    { time: "1:35 - 2:05", activity: "Workshop A", detail: "Add Logger & Generate Traffic" },
    { time: "2:05 - 2:25", activity: "Live Demo 3", detail: "Mini Monitoring Dashboard (Streamlit)" },
    { time: "2:25 - 2:40", activity: "Live Demo 4", detail: "Model Versioning & Incident Runbook" },
    { time: "2:40 - 2:50", activity: "Workshop B", detail: "Create Docs: Privacy Policy, Runbook, Registry" },
    { time: "2:50 - 3:00", activity: "Wrap-up & Quiz", detail: "Final check & Quiz" }
  ],
  contentSummary: [
    { title: "Structured Logging", points: ["Log events as JSON lines (JSONL).", "Easy to parse and analyze."] },
    { title: "Key Metrics", points: ["Error Rate, Latency (p95), Request Volume.", "Drift Signals: Error/Latency spikes."] },
    { title: "Operations Docs", points: ["Runbook: Steps to fix incidents.", "Model Registry: Track versions (v5, v6)."] }
  ],
  demoScript: [
    { step: "1. api/logger.py", description: "Safe JSON logger", code: "def append_log(event): with open('logs.jsonl', 'a') as f: f.write(json.dumps(event)+'\\n')" },
    { step: "2. src/metrics.py", description: "Calculate stats", code: "df = pd.read_json('logs.jsonl', lines=True)\nprint(df['status'].value_counts())" },
    { step: "3. monitor/app.py", description: "Dashboard", code: "st.metric('Total Requests', len(df))\nst.metric('Error Rate', error_rate)" }
  ],
  workshopSteps: [
    { title: "Workshop A: Logging", steps: ["Create api/logger.py", "Integrate into main.py (Success/Error)", "Generate logs by using the app"] },
    { title: "Workshop B: Ops", steps: ["Build Monitor Dashboard", "Write Privacy Policy", "Write Incident Runbook"] }
  ],
  exercises: [
    { level: "Easy", title: "Time Filter", description: "Add a slider to filter logs by last 1 hour in Dashboard" },
    { level: "Medium", title: "Error Budget", description: "Show warning if Error Rate > 5%" },
    { level: "Challenge", title: "Drift Signal", description: "Plot histogram of prediction probabilities to detect drift" }
  ],
  debugCorner: [
    { problem: "Logs not created", solution: "Check directory permissions & ensure API is called" },
    { problem: "JSON Decode Error", solution: "Skip empty lines in metrics script" },
    { problem: "Missing Latency", solution: "Calculate time.time() difference before logging" }
  ],
  quiz: [
    { id: 1, question: "Logs vs Metrics?", options: ["Same thing", "Logs=Events, Metrics=Numbers", "Metrics have PII", "Logs are useless"], correctAnswer: 1, explanation: "Logs detail individual events; Metrics aggregate them into trends." },
    { id: 2, question: "Best format for logs?", options: ["Random text", "JSONL (Structured)", "PNG", "SQL"], correctAnswer: 1, explanation: "JSONL is machine-readable and easy to parse." },
    { id: 3, question: "What must NOT be logged?", options: ["Request ID", "Latency", "Raw User PII", "Model Version"], correctAnswer: 2, explanation: "Never log PII or raw input data to protect privacy." },
    { id: 4, question: "Important API Metrics?", options: ["UI Color", "Error Rate & Latency p95", "File count", "Repo size"], correctAnswer: 1, explanation: "These indicate the health and performance of the service." },
    { id: 5, question: "First step in incident?", options: ["Change model", "Check Logs & Health", "Delete logs", "Stop UI"], correctAnswer: 1, explanation: "Diagnose before acting." },
    { id: 6, question: "Model Registry contains?", options: ["Friend list", "Versions + Artifacts + Policy", "Just model file", "Demo images"], correctAnswer: 1, explanation: "It tracks model lineage and deployment rules." },
    { id: 7, question: "Simple Drift Signal?", options: ["Train accuracy", "Error/Latency Spikes", "Graph color", "RAM usage"], correctAnswer: 1, explanation: "Sudden changes in operational metrics often indicate drift." },
    { id: 8, question: "Runbook purpose?", options: ["Better accuracy", "Systematic Incident Response", "Smaller docker", "Faster UI"], correctAnswer: 1, explanation: "A guide for operators to resolve issues quickly." },
    { id: 9, question: "Risk of keeping logs too long?", options: ["Port conflict", "Privacy/Space issues", "Lower accuracy", "Changed requirements"], correctAnswer: 1, explanation: "Logs consume space and increase privacy risk over time." },
    { id: 10, question: "Week 11 DoD?", options: ["Dashboard only", "Logs + Metrics + Dashboard + Docs", "Cloud URL", "Capstone done"], correctAnswer: 1, explanation: "A complete monitoring loop with documentation." }
  ]
};

export const WEEK_12_LESSON_PLAN: LessonPlan = {
  week: 12,
  topic: "Capstone Wrap-up (Enterprise)",
  timeline: [
    { time: "0:00 - 0:10", activity: "Recap & Goals", detail: "Review full stack journey. Goal: Finalize for Enterprise Release." },
    { time: "0:10 - 0:25", activity: "Portfolio Storytelling", detail: "How to pitch your project: Problem -> Solution -> Impact." },
    { time: "0:25 - 0:50", activity: "Live Demo 1", detail: "Create a Pro README (Structure, Demo Links, Instructions)." },
    { time: "0:50 - 1:20", activity: "Live Demo 2", detail: "Enterprise Docs: Charter, Datasheet, Model Card, Test Plan." },
    { time: "1:20 - 1:55", activity: "Workshop A", detail: "Complete README & Documentation Pack." },
    { time: "1:55 - 2:20", activity: "Live Demo 3", detail: "Final QA Checklist (Security, PDPA, E2E Tests)." },
    { time: "2:20 - 2:35", activity: "Live Demo 4", detail: "Release Management: Git Tags & Changelog." },
    { time: "2:35 - 2:50", activity: "Workshop B", detail: "Final Polish, Tag Release, and 3-min Presentation Prep." },
    { time: "2:50 - 3:00", activity: "Wrap-up & Quiz", detail: "Course Completion." }
  ],
  contentSummary: [
    { title: "Portfolio Ready", points: ["Demo URL/Video, Clear README, Metrics, Enterprise Docs."] },
    { title: "Documentation", points: ["Model Card (Transparency), Datasheet (Data Origin), Runbook (Ops)."] },
    { title: "Release Discipline", points: ["Semantic Versioning (v1.0.0), Changelog, Git Tags."] }
  ],
  demoScript: [
    { step: "1. README.md", description: "Professional structure", code: "# Project Name\n## Demo\n## Solution\n## Tech Stack\n## How to Run" },
    { step: "2. Model Card", description: "docs/model_card.md", code: "## Model Details\nType: Random Forest\nVersion: v5\n## Intended Use\n..." },
    { step: "3. Git Tag", description: "Release v1.0.0", code: "git tag v1.0.0\ngit push --tags" }
  ],
  workshopSteps: [
    { title: "Workshop A: Docs", steps: ["Fill README template", "Create docs/ folder with 5 key documents", "Add screenshots"] },
    { title: "Workshop B: Release", steps: ["Run Final QA (Tests & Health)", "Create CHANGELOG.md", "Tag v1.0.0", "Rehearse Pitch"] }
  ],
  exercises: [
    { level: "Easy", title: "One-page Summary", description: "Add a concise summary section to README." },
    { level: "Medium", title: "Known Issues", description: "Document known limitations and future plans in docs/next_steps.md." },
    { level: "Challenge", title: "Makefile", description: "Create a Makefile for one-click setup/test/run." }
  ],
  debugCorner: [
    { problem: "Demo crashes", solution: "Record a fallback video. Use Docker Compose locally." },
    { problem: "Secrets in repo", solution: "Remove immediately, rotate keys, use env vars." },
    { problem: "Missing Metrics", solution: "Use data from Week 6 (Eval) or Week 11 (Monitoring)." }
  ],
  quiz: [
    { id: 1, question: "Most important for Portfolio?", options: ["Complex code", "Working Demo & Clear README", "Nice colors", "Deep Learning only"], correctAnswer: 1, explanation: "Recruiters/Clients need to see it works and understand what it does quickly." },
    { id: 2, question: "Model Card purpose?", options: ["Better accuracy", "Transparency (Usage, Limits, Metrics)", "Replace README", "Replace Tests"], correctAnswer: 1, explanation: "It explains what the model is, its intended use, and limitations." },
    { id: 3, question: "Datasheet explains?", options: ["PII storage", "Data source, collection, bias", "UI design", "Deployment speed"], correctAnswer: 1, explanation: "It documents the dataset's origin, composition, and potential biases." },
    { id: 4, question: "Runbook is for?", options: ["Higher accuracy", "Operational procedures (Start/Fix/Rollback)", "Smaller docker", "Skipping tests"], correctAnswer: 1, explanation: "It provides instructions for maintaining and troubleshooting the system." },
    { id: 5, question: "Release Tag v1.0.0?", options: ["Auto-update model", "Mark a stable, revertible point", "Load UI faster", "Remove bugs"], correctAnswer: 1, explanation: "It marks a specific point in history as a release version." },
    { id: 6, question: "Security Checklist confirms?", options: ["UI color", "No PII & No Raw Logs", "Notebook count", "Commit count"], correctAnswer: 1, explanation: "Ensures basic security and privacy standards are met." },
    { id: 7, question: "If online demo fails?", options: ["Delete repo", "Use Fallback Video/Screenshots", "Disable healthcheck", "Change language"], correctAnswer: 1, explanation: "Always have a backup plan for presentations." },
    { id: 8, question: "README Results should have?", options: ["'It works'", "Quantitative Metrics & Limitations", "Just photos", "Full code"], correctAnswer: 1, explanation: "Concrete numbers build trust and show objective performance." },
    { id: 9, question: "Go/No-Go decision based on?", options: ["Gut feeling", "QA Checklist (Tests, Health, Docs)", "Github stars", "Graph color"], correctAnswer: 1, explanation: "A systematic check ensures readiness." },
    { id: 10, question: "Week 12 DoD?", options: ["Just docs", "Full Pack (Docs, Demo, Tag, Preso)", "New model", "Change language"], correctAnswer: 1, explanation: "The complete package ready for handover or showcase." }
  ]
};

export const WORKSHOP_GUIDES: Record<string, WorkshopGuide> = {
  "track-1": {
    trackId: "track-1",
    title: "Chatbot / NLP Assistant Workshop",
    projectBrief: {
      title: "Project Brief",
      content: [
        "Goal: Build a domain-specific chatbot (e.g., HR Policy, Legal QA).",
        "Core Tech: RAG (Retrieval Augmented Generation) using Gemini or OpenAI.",
        "Interface: Streamlit Chat interface."
      ]
    },
    dataPlan: {
      title: "Data Strategy",
      content: [
        "Source: PDF Documents, Text files, or FAQ CSVs.",
        "Processing: Text Chunking (RecursiveCharacterTextSplitter).",
        "Storage: Vector Database (ChromaDB or FAISS)."
      ]
    },
    modelPlan: {
      title: "Model Architecture",
      content: [
        "LLM: Gemini-1.5-Flash (Fast & Cost-effective).",
        "Embedding: text-embedding-004.",
        "Framework: LangChain for orchestration."
      ]
    },
    notebookOutline: [
      {
        title: "1. Data Ingestion & Embedding",
        content: [
          "Load PDF files.",
          "Split text into chunks.",
          "Generate embeddings and save to VectorDB."
        ],
        code: "from langchain_community.document_loaders import PyPDFLoader\nloader = PyPDFLoader('policy.pdf')\ndocs = loader.load()"
      },
      {
        title: "2. RAG Pipeline",
        content: [
          "Create Retriever interface.",
          "Setup QA Chain with Prompt Template.",
          "Test with sample queries."
        ]
      }
    ],
    minimalCode: [
      {
        fileName: "app.py",
        language: "python",
        code: "import streamlit as st\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nst.title('AI Assistant')\n\nif 'messages' not in st.session_state:\n    st.session_state.messages = []\n\n# ... chat logic ..."
      }
    ],
    deployment: [
      {
        title: "Deployment Steps",
        content: [
          "Create `secrets.toml` for API Keys.",
          "Push to GitHub.",
          "Deploy on Streamlit Cloud."
        ]
      }
    ],
    testing: {
      title: "Testing & Eval",
      content: [
        "Test for Hallucinations (Verify answers against docs).",
        "Test with adversarial inputs (Jailbreak attempts)."
      ]
    },
    security: {
      title: "Security",
      content: [
        "Do not log user PII.",
        "Use API Key rotation."
      ]
    },
    portfolio: {
      title: "Portfolio Items",
      content: [
        "Demo Video (Screen recording).",
        "GitHub Repo with clean Readme.",
        "Sample Q&A logs."
      ]
    },
    rubric: [
      { criteria: "Retrieval Accuracy (Finds correct doc)", score: 40 },
      { criteria: "Response Quality (Clear & Concise)", score: 30 },
      { criteria: "UI/UX (Chat experience)", score: 30 }
    ]
  },
  "track-2": {
    trackId: "track-2",
    title: "Image Recognition / CV Workshop",
    projectBrief: {
      title: "Project Brief",
      content: [
        "Goal: Build an object detection or classification app (e.g., Mask Detection, Plant Disease).",
        "Core Tech: Transfer Learning or Pre-trained models (YOLO, MobileNet).",
        "Interface: Streamlit with Camera Input."
      ]
    },
    dataPlan: {
      title: "Data Strategy",
      content: [
        "Source: Kaggle, Roboflow, or Self-collected.",
        "Preprocessing: Resize, Normalize, Augmentation.",
        "Split: Train/Val/Test (70/20/10)."
      ]
    },
    modelPlan: {
      title: "Model Architecture",
      content: [
        "Base: MobileNetV2 (Feature Extractor).",
        "Head: Dense layers for custom classes.",
        "Optimizer: Adam."
      ]
    },
    notebookOutline: [
      {
        title: "1. Data Loading & Augmentation",
        content: ["Use ImageDataGenerator.", "Visualize batch of images."],
        code: "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20)"
      },
      {
        title: "2. Transfer Learning",
        content: ["Load MobileNetV2 (include_top=False).", "Add custom classification head.", "Train for 5-10 epochs."]
      }
    ],
    minimalCode: [
      {
        fileName: "app.py",
        language: "python",
        code: "import streamlit as st\nfrom PIL import Image\nimport numpy as np\n\nimg_file = st.camera_input('Take a picture')"
      }
    ],
    deployment: [
      {
        title: "Deployment",
        content: ["Ensure `requirements.txt` includes tensorflow-cpu (for lighter cloud build)."]
      }
    ],
    testing: {
      title: "Testing",
      content: ["Test with varying lighting conditions.", "Confusion Matrix analysis."]
    },
    security: {
      title: "Security",
      content: ["No saving of user images on server (Process & Forget)."]
    },
    portfolio: {
      title: "Portfolio",
      content: ["Before/After prediction screenshots.", "Accuracy plots."]
    },
    rubric: [
      { criteria: "Model Accuracy on Test Set", score: 40 },
      { criteria: "Real-time Performance", score: 30 },
      { criteria: "Error Handling (No image)", score: 30 }
    ]
  },
  "track-3": {
    trackId: "track-3",
    title: "Predictive Analytics Workshop",
    projectBrief: {
      title: "Project Brief",
      content: ["Goal: Forecast business metrics (Sales, Churn, Price).", "Core Tech: Regression/Classification on Tabular Data.", "Interface: Dashboard with Input Forms."]
    },
    dataPlan: {
      title: "Data",
      content: ["Clean CSV data.", "Handle Missing Values & Outliers.", "Feature Engineering."]
    },
    modelPlan: {
      title: "Model",
      content: ["XGBoost or Random Forest.", "Hyperparameter Tuning with GridSearchCV."]
    },
    notebookOutline: [
      { title: "EDA", content: ["Correlation Heatmap", "Distribution Plots"] },
      { title: "Modeling", content: ["Train/Test Split", "Fit Model", "Feature Importance"] }
    ],
    minimalCode: [ { fileName: "app.py", language: "python", code: "st.number_input('Input feature X')" } ],
    deployment: [ { title: "Deploy", content: ["Streamlit Cloud"] } ],
    testing: { title: "Test", content: ["Test with extreme values."] },
    security: { title: "Security", content: ["No PII in dataset."] },
    portfolio: { title: "Portfolio", content: ["Interactive Graphs."] },
    rubric: [ { criteria: "RMSE/Accuracy", score: 50 }, { criteria: "Data Insights", score: 30 }, { criteria: "Dashboard Usability", score: 20 } ]
  },
  "track-4": {
    trackId: "track-4",
    title: "IoT & Edge AI Workshop",
    projectBrief: {
      title: "Project Brief",
      content: ["Goal: AI on low-power devices.", "Core Tech: TFLite / ONNX.", "Interface: Flask API or MQTT."]
    },
    dataPlan: { title: "Data", content: ["Sensor logs."] },
    modelPlan: { title: "Model", content: ["Quantized Neural Network."] },
    notebookOutline: [ { title: "Quantization", content: ["Convert Keras model to TFLite"] } ],
    minimalCode: [ { fileName: "edge.py", language: "python", code: "interpreter = tf.lite.Interpreter(model_path='model.tflite')" } ],
    deployment: [ { title: "Deploy", content: ["Docker on Raspberry Pi"] } ],
    testing: { title: "Test", content: ["Inference Time check."] },
    security: { title: "Security", content: ["Secure MQTT connection."] },
    portfolio: { title: "Portfolio", content: ["Photo of physical setup."] },
    rubric: [ { criteria: "Performance (FPS/Latency)", score: 40 }, { criteria: "System Integration", score: 40 }, { criteria: "Docs", score: 20 } ]
  }
};